{
  "beviser": [
    {
      "bevis": "1) Produktreglen for differentialkvotient",
      "sÃ¦tning": "Hvis funktionerne ğ’‡(ğ’™) og ğ’ˆ(ğ’™) er differentiable i ğ’™ğŸ, sÃ¥ er produktet ğ’‘(ğ’™) = ğ’‡(ğ’™) â‹… ğ’ˆ(ğ’™) differentiabelt i ğ’™ğŸ med differentialkvotienten ğ’‡â€²(ğ’™ğŸ) â‹… ğ’ˆ(ğ’™ğŸ) + ğ’‡(ğ’™ğŸ) â‹… ğ’ˆâ€²(ğ’™ğŸ).",
      "udfÃ¸relse": [
        {
          "skridt": "\\Delta x = (x_0 + h) - x_0 = h",
          "argumentation": "Som sÃ¦tningen fortÃ¦ller os sÃ¥ baserer vi beviset pÃ¥ forudsÃ¦tningen om at funktionerne $f(x)$ og $g(x)$ er differentiable i punktet $x_0$. MÃ¥let med beviset er at bevise hvis en funktion $p(x)$ bestÃ¥r af produktet af to funktioner $f(x)$ og $g(x)$ som begge er differentiable i $x_0$ sÃ¥ er funktionen $p(x)$ differentiabel ved $x_0$. \n\nVi beviser at $f(x) \\cdot g(x)$ er differentiable i $x_0$ med tretrinsreglen: \n\n1. Bestem differenskvotienten \n2. Omskriv differenskvotienten \n3. UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvoitenten. \n\nDet fÃ¸rste skridt i tretrinsreglen er som sagt at bestemme differenskvotienten, og vi har to funktioner $f(x)$ og $g(x)$ som vi skal bestemme differenskvotienten for hver isÃ¦r. \n Differenskvotienten for $f(x)$ er hÃ¦ldningen af sekanten (linje der gÃ¥r gennem to punkter) der gÃ¥r gennem punkterne: \n$(x_0 , f(x_0))$ og $(x_0 + h , f(x_0 + h))$ \n\nOg differenskvotienten for $g(x)$ er hÃ¦ldningen af sekanten der gÃ¥r gennem punkterne:\n$(x_0 , g(x_0))$ og $(x_0 + h , g(x_0 + h))$ \n\nNÃ¥r vi skal bestemme differenskvotienten, gÃ¸r vi brug af to-punkts-formlen der bestemmer hÃ¦ldningen 'a' pÃ¥ en linje der gÃ¥r gennem to punkter: \n\n$a = \\frac{y_2 - y_1}{x_2 - x_1}$ \n\nFormlen bestemmer hÃ¦ldningen for en linje der gÃ¥r gennem 2 vilkÃ¥rlige punkter: $(x_1 , y_1)$ og $(x_2 , y_2)$ ved at dividere de to punkters forskel i funktionsvÃ¦rdi med de to punkters forskel i x-vÃ¦rdi. \n\nHvis vi anvender formlen pÃ¥ vores to funktioner \n$f(x)$ i punkterne $(x_0 , f(x_0))$ og $(x_0 + h , f(x_0 + h))$ \n$g(x)$ i punkterne $(x_0 , g(x_0))$ og $(x_0 + h , g(x_0 + h))$, \n\nSÃ¥ betyder det at vi kan bestemme deres differenskvotienter med disse brÃ¸ker: \n\n$\\frac{f(x_0 + h) - f(x_0)}{(x_0 + h) - x_0}$ \n\n$\\frac{g(x_0 + h) - g(x_0)}{(x_0 + h) - x_0}$ \n\nFÃ¸rste skridt i beviset er altsÃ¥ at opnÃ¥ disse to udtryk fordi at de er hver isÃ¦r differenskvotienterne for $f(x)$ og $g(x)$ . \n\nDerfor starter beviset med at reducerer udtrykket for forskellen i x-vÃ¦rdi ($\\Delta x$) mellem de to punkter, til 'h' "
        },
        {
          "skridt": "\\Delta y = p(x_0 + h) - p(x_0)",
          "argumentation": "Som formlen viser skal vi ogsÃ¥ bruge forskellen i funktionsvÃ¦rdier, $\\Delta y$ ,  til at bestemme differenskvotienten. \nDet gÃ¸res ved at trÃ¦kke de to funktionsvÃ¦rdier  $p(x_0 + h)$ og $p(x_0)$ fra hinanden"
        },
        {
          "skridt": "\\Delta y = (f(x_0 + h) \\cdot g(x_0 + h)) - (f(x_0) \\cdot g(x_0))",
          "argumentation": "Vi erstatter $p(x_0)$ og $p(x_0 + h)$ med funktionsforskriften for $p(x)$ som er givet i bevissÃ¦tningen, husk at anvend de to x-vÃ¦rdier for de to forskellige punkter som input til $f(x)$ og $g(x)$"
        },
        {
          "skridt": "\\Delta y = f(x_0 + h) \\cdot g(x_0 + h) - f(x_0) \\cdot g(x_0)",
          "argumentation": "OphÃ¦v parentesen i udtrykket da der ikke er brug for den pÃ¥ fordi man ganger fÃ¸r man dividerer"
        },
        {
          "skridt": "\\Delta y = f(x_0 + h) \\cdot g(x_0 + h) + f(x_0) \\cdot g(x_0 + h) - f(x_0) \\cdot g(x_0 + h) - f(x_0) \\cdot g(x_0)",
          "argumentation": "Vi indsÃ¦tter udtrykket: \n $- f(x_0) \\cdot g(x_0 + h) + f(x_0) \\cdot g(x_0 + h)$ \ni mellem de to led i udtrykket for $\\Delta y$. \n\nUdtrykket $f(x_0) \\cdot g(x_0 + h)$ bliver altsÃ¥ bÃ¥de tilfÃ¸jet og trukket fra, og derfor kan vi gÃ¸re det uden at Ã¦ndre pÃ¥ venstre side af lighedstegnet fordi: \n$ - f(x_0) \\cdot g(x_0 + h) + f(x_0) \\cdot g(x_0 + h) = 0$ \n\nDenne handling virker lidt tilfÃ¦ldig, men vi gÃ¸r det af to gode grunde: \n\n1. Generelt ved vi at nÃ¥r man arbejder med to funktioner som $f(x)$ og $g(x)$, i et bevis sÃ¥ gÃ¸r vi det nemmest for os selv ved at holde dem sÃ¥ adskilt som muligt. \n2. Vi ved ogsÃ¥ at vi arbejder os mod Ã©t bestemt udtryk for forskel i funktionsvÃ¦rdier for bÃ¥de $f(x)$ og for $g(x)$. \n\nDenne tilfÃ¸jelse giver os altsÃ¥ flere muligheder for at rykke rundt pÃ¥ strukturen af udtrykket for $\\Delta y$ til formÃ¥let om at hjÃ¦lpe os med at opnÃ¥ udtrykkene for de to funktioners differenskvotienter"
        },
        {
          "skridt": "\\Delta y = (f(x_0 + h) - f(x_0)) \\cdot g(x_0 + h) + f(x_0) \\cdot (g(x_0 + h) - g(x_0))",
          "argumentation": "Efter vores tilfÃ¸jelse i skridtet fÃ¸r, blev det observeret at det samlede udtryk bestod af fire led. \n\nTo af ledene: $(f(x_0 + h) \\cdot g(x_0 + h)) - f(x_0) \\cdot g(x_0 + h)$ \nBlev begge ganget med en fÃ¦lles faktor $g(x_0 + h)$ og derfor kunne vi samle dem til et led: \n$(f(x_0 + h) - f(x_0)) \\cdot g(x_0 + h)$ \n\nDe to andre led: $f(x_0) \\cdot g(x_0 + h) - f(x_0) \\cdot g(x_0)$ \nBlev begget ganget med en fÃ¦lles faktor $f(x_0)$ og derfor kunne vi samle dem til et led: \n$f(x_0) \\cdot (g(x_0 + h) - g(x_0))$ \n\nDette betyder vi har forkortet og simplificeret hele udtrykket ved at indele det i to paranteser hvor den ene ganges med $g(x_0 + h)$ og det andet ganges med $f(x_0)$ .\nDette kaldes at faktorisere udtrykket og det er det vi har gjort for at adskille de to funktioner $f(x)$ og $g(x)$ sÃ¥ meget som som muligt i udtrykket for $\\Delta y$. \n\nNu har vi reduceret udtrykket for forskel i funktionsvÃ¦rdi pÃ¥ en mÃ¥de hvor vi har adskilt de to funktioner $f(x)$ og $g(x)$ sÃ¥ meget som muligt, og vi har reduceret udtrykket for forskel i x-vÃ¦rdi (det fÃ¸rste skridt vi fortog i beviset) og derfor kan vi bevÃ¦ge os videre med at bestemme differenskvotienten."
        },
        {
          "skridt": "\\frac{\\Delta y}{\\Delta x} = \\frac{\\Delta y}{h}",
          "argumentation": "Vi opstiller udtrykket for differenskvotienten og erstatter $\\Delta x$ med 'h' som var det vi bestemte $\\Delta x$ til at vÃ¦re i fÃ¸rste skridt af beviset."
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{p(x_0 + h) - p(x_0)}{h}",
          "argumentation": "Nu erstatter vi tegnet for forskel i funktionsvÃ¦rdi, $\\Delta y$ , med funktionen $p(x)$ og forskellen mellem funktionens to funktionsvÃ¦rdier: $p(x_0)$ og $p(x_0 + h)$"
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{(f(x_0 + h) - f(x_0)) \\cdot g(x_0 + h) + f(x_0) \\cdot (g(x_0 + h) - g(x_0))}{h}",
          "argumentation": "Nu indsÃ¦tter vi det udtryk for forskel i funktionsvÃ¦rdi, $\\Delta y$, som vi reducerede os frem til tidligere og dermed har vi faktisk et udtryk for differenskvotienten for $p(x)$.\nDet er fordi vi har et udtryk der bestÃ¥r af funktionsforskriften for $p(x)$ som tager forskellen i funktionsvÃ¦rdi for $p(x)$ og dividerer den med forskellen i x-vÃ¦rdi.\n\nNu er vi altsÃ¥ nÃ¥et til nÃ¦ste skridt i tretrinsreglen: \nOmskriv differenskvotienten \n\nMed det menes at vi skal omskrive differenskvotienten til et udtryk hvor vi kender grÃ¦nsevÃ¦rdien, og i dette tilfÃ¦lde er det grÃ¦nsevÃ¦rdieRNE fordi det altsÃ¥ bÃ¥de er $f(x)$ OG $g(x)$ vi skal bestemme grÃ¦nsevÃ¦rdierne for. \n\nNÃ¥r vi siger at 'vi kender grÃ¦nsevÃ¦rdierne' for $f(x_0)$ og $g(x_0)$ og at vi skal 'omskrive differenskvotienten' sÃ¥ skal vi lige tage et kig pÃ¥ sÃ¦tningen for beviset. \n\nI bevissÃ¦tningen stÃ¥r der:'ğ’‡(ğ’™) og ğ’ˆ(ğ’™) er differentiable i ğ’™ğŸ' \n\nDenne sÃ¦tning betyder at vi ved at fÃ¸lgende gÃ¦lder: \n\n$\\lim_{h \\to 0} \\left( \\frac{f(x_0 + h) - f(x_0)}{h} \\right) = f'(x_0)$ \n\n$\\lim_{h \\to 0} \\left( \\frac{g(x_0 + h) - g(x_0)}{h} \\right) = g'(x_0)$ \n\nSÃ¥ nÃ¥r vi siger 'kender grÃ¦nsevÃ¦rdierne' betyder det at vi ved hvad der sker med henholdsvis $f(x)$ og $g(x)$ nÃ¥r vi anvender $\\lim_{h \\to 0}$\n\nVi ved altsÃ¥ hvad der sker med hÃ¦ldningen pÃ¥ linjen der gÃ¥r gennem punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$ for $f(x)$ \nVi ved ogsÃ¥ hvad der sker med hÃ¦ldningen pÃ¥ linjen der gÃ¥r gennem punkterne $(x_0, g(x_0))$ og $(x_0+h, g(x_0+h))$ for $g(x)$. \n\nMed fagord vil vi sige at vi ved at $f(x)$ og $g(x)$ er 'kontinuert' (ingen pludselige hÃ¦ldningsskift eller noget) ved $x_0$ og det vil sige hvis vi gÃ¸r forskellen mellem $x_0$ og $x_0 + h$ MEGET lille i de to funktioner, sÃ¥ ved vi at hÃ¦ldningen af denne linje vil komme meget tÃ¦t pÃ¥ den 'Ã¸jeblikkelige' hÃ¦ldning ved $x_0$ - altsÃ¥ differentialkvotienten.  \n\nAt vi skal omskrive differenskvotienten betyder altsÃ¥ at vi skal rykke rundt pÃ¥ udtrykket for $\\frac{\\Delta y}{h}$ sÃ¥ at det indeholder de to udtryk:\n\n$\\frac{f(x_0 + h) - f(x_0)}{(x_0 + h) - x_0}$ \n\n$\\frac{g(x_0 + h) - g(x_0)}{(x_0 + h) - x_0}$ \n\nOg vi sÃ¥ derfra kan anvende $\\lim_{h \\to 0}$ og vise at produktreglen gÃ¦lder for en vilkÃ¥rlig funktion $p(x)$ der er produktet af to funktioner $f(x)$ og $g(x)$ som begge er differentiable i $x_0$."
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{(f(x_0 + h) - f(x_0)) \\cdot g(x_0 + h)}{h} +  \\frac{f(x_0) \\cdot (g(x_0 + h) - g(x_0))}{h}",
          "argumentation": "Vi deler brÃ¸ken op mellem de to led fordi vi gerne vil adskille ledene til formÃ¥l om at have differenskvotienterne for $f(x)$ og $g(x)$ i udtrykket og dermed bestemme grÃ¦nsevÃ¦rdierne."
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\left( \\frac{f(x_0 + h) - f(x_0)}{h} \\right) \\cdot g(x_0 + h) + f(x_0) \\cdot \\left( \\frac{g(x_0 + h) - g(x_0)}{h} \\right)",
          "argumentation": "Vi sÃ¦tter de to faktorer: $g(x_0 + h)$ og $f(x_0)$ ned ved siden af deres brÃ¸ker for nu at have to brÃ¸ker der hver isÃ¦r kun afhÃ¦nger af Ã©n funktion. \nEndnu vigtigere, sÃ¥ har vi nu bestemt de to differenskvotienter for $f(x)$ og $g(x)$ og eftersom sÃ¦tningen for beviset siger at: 'funktionerne ğ’‡(ğ’™) og ğ’ˆ(ğ’™) er differentiable i ğ’™ğŸ' \n\n SÃ¥ ved vi at hvis forskellen i x-vÃ¦rdi mellem $x_0$ og $x_0 + h$ bliver gjort EKSTREMT lille (altsÃ¥ vÃ¦rdien for 'h' bliver gjort lille) sÃ¥ at det NÃ†STEN kan betragtes som Ã©t punkt, sÃ¥ ved vi at differenskvotinerne for $f(x)$ og $g(x)$ nÃ¦rmer sig de afledte funktioner $f'(x)$ og $g'(x)$ \n\nMed fagord vil man sige: \n'Vi ved at funktionerne for $g(x)$ og $f(x)$ er differentiable ved $x_0$ og derfor ved vi at grÃ¦nsevÃ¦rdien af differenskvotienten eksisterer i det punkt - og at den definerer differentialkvotienten'"
        },
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\lim_{h \\to 0} \\left( \\left( \\frac{f(x_0 + h) - f(x_0)}{h} \\right) \\cdot g(x_0 + h) + f(x_0) \\cdot \\left( \\frac{g(x_0 + h) - g(x_0)}{h} \\right) \\right)",
          "argumentation": "Vi er noget til tredje skridt i tretrinsreglen: \nUndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvotienten \n\nVi skal altsÃ¥ bestemme differentialkvotienten ved at bestemme grÃ¦nsevÃ¦rdierne.\n\nFor at bestemme grÃ¦nsevÃ¦rdierne til de to differenskvotienter og dermed differentialkvotienterne, skal vi som sagt minimere forskellen, 'h', sÃ¥ meget som muligt og det gÃ¸r vi ved brug af $\\lim_{h \\to 0}$ som egentlig bare betyder at 'h' bliver ekstremt lille men IKKE 0."
        },
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = f'(x_0) \\cdot g(x_0) + f(x_0) \\cdot g'(x_0)",
          "argumentation": "Nu har vi bestemt $f'(x)$ og $g'(x)$ ogsÃ¥ kaldt differentialkvotienterne for henholdsvis $f(x)$ og $g(x)$ med tretrinsreglen.\n\n Vi vidste at de to funktioner var differentiable i punktet $x_0$. \nMed den viden kunne vi fÃ¸rst gÃ¥ efter at bestemme differenskvotienterne for funktionerne og derefter bruge $\\lim_{h \\to 0}$ til at bestemme grÃ¦nsevÃ¦rdierne for differenskvotienterne som gav differentialkvotienterne."
        },
        {
          "skridt": "p'(x_0) = f'(x_0) \\cdot g(x_0) + f(x_0) \\cdot g'(x_0)",
          "argumentation": "Nu erstattes '$\\lim_{h \\to 0} \\frac{\\Delta y}{h}$' med differentialkvotienten til $p(x_0)$ fordi vi har kunne succesfuldt bruge $\\lim_{h \\to 0}$ pÃ¥ differenskvotienten for $p(x)$ ved at omskrive differenskvotienten til et udtryk der indeholdte differenskvotienterne for $f(x)$ og $g(x)$ og derefter bestemme grÃ¦nsevÃ¦rdierne for disse.\n\nDette betyder at vi har bevist at $p(x)$ er differentiable i $x_0$ og at differentialkvotienten til $p(x)$ er $f'(x_0) \\cdot g(x_0) + f(x_0) \\cdot g'(x_0)$. \n\nDette er altsÃ¥ det vi ville bevise og derfor er beviset nu fÃ¦rdigt."
        },
        {
          "skridt": "",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"
        }
      ]
    },
    {
      "bevis": "1) Regneregel for sum af differentialkvotient",
      "sÃ¦tning": "Hvis funktionerne ğ’‡(ğ’™) og ğ’ˆ(ğ’™) er differentiable i ğ’™ğŸ, sÃ¥ er summen ğ’‘(ğ’™) = ğ’‡(ğ’™) + ğ’ˆ(ğ’™) differentiabel i ğ’™ğŸ med differentialkvotienten ğ’‡â€²(ğ’™ğŸ) + ğ’ˆâ€²(ğ’™ğŸ).",
      "udfÃ¸relse": [
        {
          "skridt": "\\Delta x = (x_0 + h) - x_0 = h",
          "argumentation": "Som sÃ¦tningen fortÃ¦ller os sÃ¥ baserer vi beviset pÃ¥ forudsÃ¦tningen om at funktionerne $f(x)$ og $g(x)$ er differentiable i punktet $x_0$. MÃ¥let med beviset er at bevise hvis en funktion $p(x)$ bestÃ¥r af summen af to funktioner $f(x)$ og $g(x)$ som begge er differentiable ved $x_0$ sÃ¥ er funktionen $p(x)$ differentiabel ved $x_0$. \n\nVi beviser at $f(x) + g(x)$ er differentiable i $x_0$ med tretrinsreglen: \n\n1. Bestem differenskvotienten \n2. Omskriv differenskvotienten \n3. UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvotienten. \n\nDet fÃ¸rste skridt i tretrinsreglen er som sagt at bestemme differenskvotienten, og vi har to funktioner $f(x)$ og $g(x)$ som vi skal bestemme differenskvotienten for hver isÃ¦r. \n Differenskvotienten for $f(x)$ er hÃ¦ldningen af sekanten (linje der gÃ¥r gennem to punkter) der gÃ¥r gennem punkterne: \n$(x_0 , f(x_0))$ og $(x_0 + h , f(x_0 + h))$ \n\nOg differenskvotienten for $g(x)$ er hÃ¦ldningen af sekanten der gÃ¥r gennem punkterne:\n$(x_0 , g(x_0))$ og $(x_0 + h , g(x_0 + h))$ \n\nNÃ¥r vi skal bestemme differenskvotienten, gÃ¸r vi brug af to-punkts-formlen der bestemmer hÃ¦ldningen 'a' pÃ¥ en linje der gÃ¥r gennem to punkter: \n\n$a = \\frac{y_2 - y_1}{x_2 - x_1}$ \n\nFormlen bestemmer hÃ¦ldningen for en linje der gÃ¥r gennem 2 vilkÃ¥rlige punkter: $(x_1 , y_1)$ og $(x_2 , y_2)$ ved at dividere de to punkters forskel i funktionsvÃ¦rdi med de to punkters forskel i x-vÃ¦rdi. \n\nHvis vi anvender formlen pÃ¥ vores to funktioner \n$f(x)$ i punkterne $(x_0 , f(x_0))$ og $(x_0 + h , f(x_0 + h))$ \n$g(x)$ i punkterne $(x_0 , g(x_0))$ og $(x_0 + h , g(x_0 + h))$, \n\nSÃ¥ betyder det at vi kan bestemme deres differenskvotienter med disse brÃ¸ker: \n\n$\\frac{f(x_0 + h) - f(x_0)}{(x_0 + h) - x_0}$ \n\n$\\frac{g(x_0 + h) - g(x_0)}{(x_0 + h) - x_0}$ \n\nFÃ¸rste skridt i beviset er altsÃ¥ at opnÃ¥ disse to udtryk fordi at de er hver isÃ¦r differenskvotienterne for $f(x)$ og $g(x)$ . \n\nDerfor starter beviset med at reducerer udtrykket for forskellen i x-vÃ¦rdi ($\\Delta x$) mellem de to punkter, til 'h' "
        },
        {
          "skridt": "\\Delta y = p(x_0 + h) - p(x_0)",
          "argumentation": "Som formlen viser skal vi ogsÃ¥ bruge forskellen i funktionsvÃ¦rdier, $\\Delta y$ ,  til at bestemme differenskvotienten. \nDet gÃ¸res ved at trÃ¦kke de to funktionsvÃ¦rdier  $p(x_0 + h)$ og $p(x_0)$ fra hinanden"
        },
        {
          "skridt": "\\Delta y = (f(x_0 + h) + g(x_0 + h)) - (f(x_0) + g(x_0))",
          "argumentation": "Vi erstatter $p(x_0)$ og $p(x_0 + h)$ med funktionsforskriften for $p(x)$ som er givet i bevissÃ¦tningen, husk at anvend de to x-vÃ¦rdier for de to forskellige punkter som input til $f(x)$ og $g(x)$"
        },
        {
          "skridt": "\\Delta y = f(x_0 + h) + g(x_0 + h) - f(x_0) - g(x_0)",
          "argumentation": "OphÃ¦ver parentesen i udtrykket og Ã¦ndre fortegn i den negative parentes."
        },
        {
          "skridt": "\\Delta y = f(x_0 + h) - f(x_0) + g(x_0 + h) - g(x_0)",
          "argumentation": "Vi rykker rundt pÃ¥ udtrykket for at holde de to funktioner sÃ¥ adskilt som muligt"
        },
        {
          "skridt": "\\frac{\\Delta y}{\\Delta x} = \\frac{\\Delta y}{h}",
          "argumentation": "Vi opstiller udtrykket for differenskvotienten og erstatter $\\Delta x$ med 'h' som var det vi bestemte $\\Delta x$ til at vÃ¦re i fÃ¸rste skridt af beviset."
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{p(x_0 + h) - p(x_0)}{h}",
          "argumentation": "Nu erstatter vi tegnet for forskel i funktionsvÃ¦rdi, $\\Delta y$ , med funktionen $p(x)$ og forskellen mellem funktionens to funktionsvÃ¦rdier: $p(x_0)$ og $p(x_0 + h)$"
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{f(x_0 + h) - f(x_0) + g(x_0 + h) - g(x_0)}{h}",
          "argumentation": "Nu indsÃ¦tter vi det udtryk for forskel i funktionsvÃ¦rdi, $\\Delta y$, som vi reducerede os frem til tidligere og dermed har vi et udtryk for differenskvotienten for $p(x)$.\nDet er fordi vi har et udtryk der bestÃ¥r af funktionsforskriften for $p(x)$ som tager forskellen i funktionsvÃ¦rdi for $p(x)$ og dividerer den med forskellen i x-vÃ¦rdi.\n\nNu er vi altsÃ¥ nÃ¥et til nÃ¦ste skridt i tretrinsreglen: \nOmskriv differenskvotienten \n\nMed det menes at vi skal omskrive differenskvotienten til et udtryk hvor vi kender grÃ¦nsevÃ¦rdien, og i dette tilfÃ¦lde er det grÃ¦nsevÃ¦rdieRNE fordi det altsÃ¥ bÃ¥de er $f(x)$ OG $g(x)$ vi skal bestemme grÃ¦nsevÃ¦rdierne for. \n\nFor at forstÃ¥ hvad der menes nÃ¥r vi siger at 'vi kender grÃ¦nsevÃ¦rdierne' for $f(x)$ og $g(x)$ og at vi skal 'omskrive differenskvotienten' sÃ¥ skal vi lige tage et kig pÃ¥ sÃ¦tningen for beviset. \n\nI bevissÃ¦tningen stÃ¥r der:'ğ’‡(ğ’™) og ğ’ˆ(ğ’™) er differentiable i ğ’™ğŸ' \n\nDenne sÃ¦tning betyder at vi ved at fÃ¸lgende gÃ¦lder: \n\n$\\lim_{h \\to 0} \\left( \\frac{f(x_0 + h) - f(x_0)}{h} \\right) = f'(x_0)$ \n\n$\\lim_{h \\to 0} \\left( \\frac{g(x_0 + h) - g(x_0)}{h} \\right) = g'(x_0)$ \n\nSÃ¥ nÃ¥r vi siger 'kender grÃ¦nsevÃ¦rdierne' betyder det at vi ved hvad der sker med henholdsvis $f(x)$ og $g(x)$ nÃ¥r vi anvender $\\lim_{h \\to 0}$\n\nVi ved altsÃ¥ hvad der sker med hÃ¦ldningen pÃ¥ linjen der gÃ¥r gennem punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$ for $f(x)$ \nVi ved ogsÃ¥ hvad der sker med hÃ¦ldningen pÃ¥ linjen der gÃ¥r gennem punkterne $(x_0, g(x_0))$ og $(x_0+h, g(x_0+h))$ for $g(x)$. \n\nMed fagord vil vi sige at vi ved at $f(x)$ og $g(x)$ er 'kontinuere' (ingen pludselige hÃ¦ldningsskift eller noget) ved $x_0$ og det vil sige hvis vi gÃ¸r forskellen mellem $x_0$ og $x_0 + h$ MEGET lille i de to funktioner, sÃ¥ ved vi at hÃ¦ldningen af denne linje vil komme meget tÃ¦t pÃ¥ den 'Ã¸jeblikkelige' hÃ¦ldning ved $x_0$ - altsÃ¥ differentialkvotienten.  \n\nAt vi skal omskrive differenskvotienten betyder altsÃ¥ at vi skal rykke rundt pÃ¥ udtrykket for $\\frac{\\Delta y}{h}$ sÃ¥ at det indeholder de to udtryk:\n\n$\\frac{f(x_0 + h) - f(x_0)}{(x_0 + h) - x_0}$ \n\n$\\frac{g(x_0 + h) - g(x_0)}{(x_0 + h) - x_0}$ \n\nOg vi sÃ¥ derfra kan anvende $\\lim_{h \\to 0}$ og vise at produktreglen gÃ¦lder for en vilkÃ¥rlig funktion $p(x)$ der er produktet af to funktioner $f(x)$ og $g(x)$ som begge er differentiable i $x_0$."
        },
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{f(x_0 + h) - f(x_0)}{h} + \\frac{g(x_0 + h) - g(x_0)}{h}",
          "argumentation": "Vi deler brÃ¸ken op mellem de to led fordi vi gerne vil adskille ledene til formÃ¥l om at have differenskvotienterne for $f(x)$ og $g(x)$ i udtrykket og dermed bestemme grÃ¦nsevÃ¦rdierne. Nu er andet skridt klaret fordi vi har omskrevet differenskvotienten til et udtryk der indeholder differenskvotienterne for $f(x)$ og $g(x)$"
        },
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\lim_{h \\to 0} (\\frac{f(x_0 + h) - f(x_0)}{h} + \\frac{g(x_0 + h) - g(x_0)}{h})",
          "argumentation": "Vi er noget til tredje skridt i tretrinsreglen: \nUndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvotienten \n\nVi skal altsÃ¥ bestemme differentialkvotienten ved at bestemme grÃ¦nsevÃ¦rdierne.\n\nFor at bestemme grÃ¦nsevÃ¦rdierne til de to differenskvotienter og dermed differentialkvotientern, skal vi som sagt minimere forskellen, 'h', sÃ¥ meget som muligt og det gÃ¸r vi ved brug af $\\lim_{h \\to 0}$ som egentlig bare betyder at 'h' bliver ekstremt lille men IKKE 0."
        },
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\lim_{h \\to 0} \\frac{f(x_0 + h) - f(x_0)}{h} + \\lim_{h \\to 0} \\frac{g(x_0 + h) - g(x_0)}{h}",
          "argumentation": "Nu finder vi grÃ¦nsevÃ¦rdierne for de to differenskvotienter $f(x)$ og $g(x)$ \n\nOg dermed differentialkvotienten for dem og $p(x_0)$"
        },
        {
          "skridt": "p'(x_0) = f'(x_0) + g'(x_0)",
          "argumentation": "Nu erstattes '$\\lim_{h \\to 0} \\frac{\\Delta y}{h}$' med differentialkvotienten til $p(x_0)$ fordi vi har kunne succesfuldt bruge $\\lim_{h \\to 0}$ pÃ¥ differenskvotienten for $p(x)$ ved at omskrive differenskvotienten til et udtryk der indeholdte differenskvotienterne for $f(x)$ og $g(x)$ og derefter bestemme grÃ¦nsevÃ¦rdierne for disse.\n\nDette betyder at vi har bevist at $p(x)$ er differentiable i $x_0$ og at differentialkvotienten til $p(x)$ er $f'(x_0) + g'(x_0)$. \n\nDette er altsÃ¥ det vi ville bevise og derfor er beviset nu fÃ¦rdigt."
        },
        {
          "skridt": "p'(x_0) = f'(x_0) + g'(x_0)",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"
        }
    ]
    },
    {
      "bevis": "2/4) Bevis for arealfunktionen er en stamfunktion",
      "sÃ¦tning": "SÃ¦tning: Arealfunktionen ğ‘¨(ğ’™) for en kontinuert funktion ğ’‡(ğ’™) er differentiabel, og der gÃ¦lder:\nğ‘¨â€²(ğ’™) = ğ’‡(ğ’™)\n(Dvs. arealfunktionen ğ‘¨(ğ’™) er en stamfunktion til ğ’‡(ğ’™))",
      "udfÃ¸relse": [
        {
          "skridt": "Introduktion",
          "argumentation": "Inden vi beviser at arealfunktionen, $A(x)$, er en stamfunktion af den funktion $f(x)$ hvor arealet mellem dens graf og x-aksen er hvad der beskrives, sÃ¥ redegÃ¸rer vi lige for nogle overordnede ting. $A(x)$ er ogsÃ¥ differentiabel. \n\n$A(x)$ er en funktion der beskriver arealet mellem en graf $f(x)$ og x-aksen i omrÃ¥det $[a, x]$.\n\n$f(x)$ har fÃ¸lgende egenskaber som er vigtige at huske til beviset:\n$f(x)$ er en kontinuer funktion, Dvs. at den er differentiabel i hele sit interval altsÃ¥ vi kender grÃ¦nsevÃ¦rdien. \n$f(x)$ lÃ¸ber i intervallet $[a, b]$ og dens funktionsvÃ¦rdi vil altid vÃ¦re lig 0 eller positiv:\n $f(x) â‰¥ 0$ \n\nHUSK: til eksamen sÃ¥ gerne inddrag nogle af tegningerne fra fÃ¸rste side af beviskompendiet til at forklare denne del."},
        {
          "skridt": "BEVIS",
          "argumentation": "SÃ¦tning:\nArealfunktionen ğ‘¨(ğ’™) for en kontinuert funktion ğ’‡(ğ’™) er differentiabel, og der gÃ¦lder: ğ‘¨â€²(ğ’™) = ğ’‡(ğ’™)(Dvs. arealfunktionen ğ‘¨(ğ’™) er en stamfunktion til ğ’‡(ğ’™))\n\nEfter redegÃ¸relsen af hvad vi mener nÃ¥r vi siger 'arealfunktion' sÃ¥ beviser vi at arealfunktionen, $A(x)$, er en stamfunktion til $f(x)$. \n\nSelvom vi skal bevise at $A(x)$ er en stamfunktion, sÃ¥ starter vi fra et lidt andet sted.\n Vi vÃ¦lger faktisk at bevise at $f(x)$ er differentialkvotienten til $A(x)$. \nDet gÃ¸r vi fordi at vi ved at den afledte af en stamfunktion er lig funktionen som stamfunktionen er en stamfunktion til: \n\n$\\int f(x)\\,dx = F(x)+k \\Leftrightarrow F'(x)=f(x) $ \n\nDerfor kan beviset anskues lidt som et differentialregningsbevis fordi at vi faktisk beviser at funktionen $f(x)$ er differentialkvotienten til $A(x)$ og pÃ¥ den mÃ¥de beviser vi ogsÃ¥ at $A(x)$ er en stamfunktion til $f(x)$\n\nDerfor bruger vi tretrinsreglen til at udfÃ¸re beviset:\n\n 1.Bestem differenskvotienten\n2.Omskriv differenskvotienten\nUndersÃ¸g om differens.\n3.UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvotienten."},
        {
          "skridt": "\\Delta A = A(x_0 + h) - A(x_0)",
          "argumentation": "Vi bestemmer forskellen i funktionsvÃ¦rdi for $A(x)$ i punkterne $(x_0, A(x_0))$ og $(x_0+h, A(x_0+h))$. \n\nHusk $A(x)$ er den funktion hvis differentialkvotient vi skal bestemme til at vÃ¦re $f(x)$. \n\nHusk ogsÃ¥ det der gÃ¸r det her bevis anderledes fra normale differentialregningsbeviser er at vi ikke er givet nogen funktionsforskrift for $A(x)$ eller $f(x)$ men vi ved at $A(x)$ beskriver arealet mellem grafen $f(x)$ og x-aksen i intervallet $[a, x]$ \nHvor $a$ er den laveste x-vÃ¦rdi $f(x)$ kan have.\n\nI fÃ¸rste skridt af selve beviset viser vi sÃ¥ at arealet af omrÃ¥det mellem grafen $f(x)$ og fÃ¸rsteaksen i intervallet $[x_0, x_0+h]$ er bestemt til at vÃ¦re $\\Delta A$."},
        {
          "skridt": "\\frac{\\Delta A}{h} = \\frac{A(x_0 + h) - A(x_0)}{h}",
          "argumentation": "Nu er differenskvotienten for $A(x)$ bestemt  ved at dividere forskellen i funktionsvÃ¦rdi med forskellen i x-vÃ¦rdi. I teorien behÃ¸ver vi ikke at omskrive differenskvotienten  til noget nyt for at kunne bestemme differentialkvotienten fordi som bevissÃ¦tningen siger: \n\n'Arealfunktionen ğ‘¨(ğ’™) for en kontinuert funktion ğ’‡(ğ’™) er differentiabel' \n\n Det betyder jo at vi ved hvad der sker med differenskvotienten til $A(x)$ nÃ¥r vi laver $\\lim{h \\to 0}$ fordi vi kender grÃ¦nsevÃ¦rdien. Problemet er bare at vi ikke har nogen funktionsforskrift for $A(x)$ sÃ¥ lige nu vil det ikke lÃ¦re os noget nyt om $A(x)$."},
        {
          "skridt": "f(x_0) \\cdot h â‰¤ \\Delta A â‰¤ f(x_0+h) \\cdot h",
          "argumentation": "Normalt vil vi skulle omskrive differenskvotienten for $A(x)$, men som nÃ¦vnt tidligere sÃ¥ er vi ikke givet nogle funktionsforskrift for $A(x)$ sÃ¥ vi kan ikke omskrive differenskvotienten til noget nyt fordi vi ved jo ikke rigtigt noget om hvordan funktionsforskriften for $A(x)$ ser ud. \n\nMen det er faktisk okay fordi vi kan lave et lille trick pÃ¥ baggrund af hvad vi ellers ved indtil videre.\n\nVi ved fra fÃ¸rste skridt i beviset at $\\Delta A$ er arealet mellem grafen $f(x)$ og x-aksen i omrÃ¥det $[x_0, x_0+h]$.\n\n Vi ved faktisk ogsÃ¥ to andre vigtige ting:\n\nVi ved at arealet af rektanglet som har hÃ¸jden af $f(x)$ i punktet $(x_0, f(x_0))$ og bredden $h$ er mindre end eller lig med arealet mellem grafen for $f(x)$ og x-aksen i omrÃ¥det $[x_0, x_0+h]$ altsÃ¥ $\\Delta A$. \n\nVi ved ogsÃ¥ at arealet af rektanglet som har hÃ¸jden af $f(x)$ i punktet $(x_0+h, f(x_0+h))$ og bredden $h$ er stÃ¸rre end eller lig med arealet mellem grafen for $f(x)$ og x-aksen i omrÃ¥det $[x_0, x_0+h]$ altsÃ¥ det vi har defineret som $\\Delta A$. (Kig gerne pÃ¥ tegningen i beviset for illustration) \n\nGrunden til at det KAN ske at $\\Delta A$ er lig med mindre eller stÃ¸rre rektangel er at hvis funktionen $f(x)$ er konstant (flad) i intervallet $[x_0, x_0+h]$."},
        {
          "skridt": "\\frac{f(x_0) \\cdot \\cancel{h}}{\\cancel{h}} â‰¤ \\frac{\\Delta A}{h} â‰¤ \\frac{f(x_0+h) \\cdot \\cancel{h}}{\\cancel{h}} \\Leftrightarrow f(x_0) â‰¤ \\frac{\\Delta A}{h} â‰¤ f(x_0+h)",
          "argumentation": "Vi dividerer med 'h' for at fÃ¥ differenskvotienten for $A(x)$.\n\n Nu ved vi lige pludselig lidt mere om differenskvotienten for $A(x)$ fordi at vi nu har 'klemt' den imellem to forskellige funktionsvÃ¦rdier fra den samme funktion.  \n\nVed at tage en lille omvej har altsÃ¥ vi lÃ¦rt lidt mere om differenskvotienten for $A(x)$. \nUdtrykket siger altsÃ¥ nu at differenskvotienten for $A(x)$ er stÃ¸rre end eller lig med $f(x)$ i punktet $(x_0, f(x_0))$ og at den er mindre end eller lig med $f(x)$ i punktet $(x_0+h, f(x_0+h))$."},
        {
          "skridt": "f(x_0) â‰¤ \\frac{A(x_0+h)-A(x_0)}{h} â‰¤ f(x_0+h)",
          "argumentation": "Nu erstatter vi tegnet for differenskvotienten for $A(x)$ med udtrykket for forskellen i $A(x)$ 's funktionsvÃ¦rdi."},
        {
          "skridt": "\\lim_{h \\to 0} f(x_0) \\leq \\lim_{h \\to 0} \\frac{A(x_0 + h) - A(x_0)}{h} \\leq \\lim_{h \\to 0} f(x_0 + h) \\Leftrightarrow f(x_0) â‰¤ \\frac{A(x_0+h)-A(x_0)}{h} â‰¤ f(x_0)",
          "argumentation": "Nu bestemmer vi sÃ¥ grÃ¦nsevÃ¦rdien ved at anvende $\\lim_{h \\to 0}$ pÃ¥ alle tre dele af udtrykket, og det gÃ¸r vi fÃ¸rst nu fordi at det ikke pÃ¥virker fÃ¸rst del: $f(x_0)$ fordi at den ikke afhÃ¦nger af 'h' og derfor vil en Ã¦ndring af 'h' ikke pÃ¥virke $f(x_0)$. \n\nUdover det sÃ¥ Ã¦ndre $\\lim_{h \\to 0}$ sidste del til at blive det samme som fÃ¸rste del fordi det eneste der adskilte $f(x_0)$ og $f(x_0+h)$ var 'h', og 'h' bliver jo sÃ¥ tÃ¦t pÃ¥ 0 at vi bare kan fjerne 'h' i udtrykket eftersom det bare stÃ¥r som del af input til en funktoin. \n\nDenne handling efterlader os altsÃ¥ med et udtryk der siger at grÃ¦nsevÃ¦rdien for differenskvotienten for $A(x)$ er stÃ¸rre eller lig med $f(x)$ i punktet $(x_0, f(x_0))$. Og mindre eller lig med $f(x)$ i punktet $(x_0, f(x_0))$."}, 
        {
          "skridt": "f(x_0) â‰¤ \\frac{A(x_0+h)-A(x_0)}{h} â‰¤ f(x_0) \\Leftrightarrow f(x_0) = \\frac{A(x_0+h)-A(x_0)}{h} = f(x_0) \\Leftrightarrow \\frac{A(x_0+h)-A(x_0)}{h} = f(x_0)",
          "argumentation": "PÃ¥ baggrund af anvendelsen af $\\lim_{h \\to 0}$ og kan vi Ã¦ndre '$â‰¤$' til '$=$'."},
        {
          "skridt": "A'(x_0) = f(x_0)",
          "argumentation": "Som sagt kender vi grÃ¦nsevÃ¦rdien for differenskvotienten til $A(x_0)$ sÃ¥ nÃ¥r vi anvender $\\lim_{h \\to 0}$ pÃ¥ differenskvotienten for $A(x)$ sÃ¥ fÃ¥r vi differentialkvotienten for $A(x)$."},
        {
          "skridt": "A'(x_0) = f(x_0)",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$."},
        {
          "skridt": "Areal",
          "argumentation": "Nu har vi bevist at $A'(x) = f(x)$ og dermed at arealfunktionen $A(x)$ er en stamfunktion til $f(x)$.\n\nMen for at afslutte denne forklaring om arealfunktioner skal vi lige tage et skridt tilbage til fÃ¸rste del af beviset.\nHer forklarede vi at $A(x)$ bestemmer arealet mellem grafen for $f(x)$ der lÃ¸ber i intervallet $[a, c]$ og x-aksen i intervallet $[a, x]$. Med dette kunne vi ogsÃ¥ konkludere at for at bestemme arealet af et bestemt omrÃ¥de $[a, b]$ mellem grafen for $f(x)$ og x-aksen, sÃ¥ kan vi gÃ¸re dette: \n$A(b)-A(a)$ \n\n Lige fÃ¸r beviste vi at $A(x)$ bare er Ã©n ud af et uendeligt antal stamfunktioner til en funktion $f(x)$, og alle disse forskellige stamfunktioner er adskilt af en konstant $k$ som kan vÃ¦re forskellig. Men eftersom vi i starten definerede arealet i et bestemt omrÃ¥de med: \n$A(b)-A(a)$  \n\nOg vi ved at: \n\n$A(x)=F(x)+k$ \n\nSÃ¥ selvom at en stamfunktion ikke har den samme $k$ vÃ¦rdi som arealfunktionen, men nÃ¥r vi laver udregningen pÃ¥ den her mÃ¥de:\n\n$A(b)-A(a)=F(b)+k-(F(a)+k) \\Leftrightarrow A(b)-A(a)=F(b)+k-F(a)-k$\n\n $k$ gÃ¥r ud md sig selv.\n\n$A(b)-A(a)=F(b)-F(a)$ \n\nSÃ¥ bliver tallet $k$ som var det eneste der adskilte arealfunktionen fra andre stamfunktioner alligevel slettet og derfor kan vi bruge en hvilken som helst stamfunktion til at bestemme arealet mellem grafen for $f(x)$ og x-aksen i et bestemt omrÃ¥de."}
          ]
        },
{
    "bevis": "3) MiddelvÃ¦rdi og spredning",
    "sÃ¦tning": "SÃ¦tning: For en stokastisk variabel ğ‘¿ der er binomialfordelt med antalsparameter ğ’ og sandsynlighedsparameter ğ’‘, er middelvÃ¦rdien, ğ, givet ved ğ = ğ’ â‹… ğ’‘",
    "udfÃ¸relse": [
      {
        "skridt": "Introduktion",
        "argumentation": "Vi skal bevise formlen for middelvÃ¦rdien for en binomialfordelt stokastisk variabel X. FÃ¸rst skal vi lave et lille bevis for en specifik omskrivining af binomialkoefficienten ganget med antallet af succeser $r$ som vi kommer til at bruge i beviset for middelvÃ¦rdien til en binomialfordelt stokastisk variabel X med antalsparameter $n$ og sandsynlighedsparameter $p$."},
      {
        "skridt": "ğ‘Ÿ â‹… k(n, r) = n â‹… k(n âˆ’ 1, r âˆ’ 1)",
        "argumentation": "Bevis for hjÃ¦lpesÃ¦tning: For de to binomialkoefficenter ğ‘²(ğ’, ğ’“) og ğ‘²(ğ’ âˆ’ ğŸ, ğ’“ âˆ’ ğŸ) gÃ¦lder fÃ¸lgende sammenhÃ¦ng: ğ‘Ÿ â‹… $K(n, r) = n \\cdot ğ¾(n âˆ’ 1, r âˆ’ 1)$\n\nVi beviser en omskrivning af udtrykket for binomialkoefficienten ganget med antallet af succeser $r$.\n\nBinomialkoefficienten tager et antal successer $r$ og bestemmer antallet af mÃ¥der man kan fÃ¥ $r$ succeser i $n$ forsÃ¸g. De $n$ forsÃ¸g er fast bestemt for hele binomialfordelingen og kan ikke blive Ã¦ndret pÃ¥. \n\n Formlen for binomialkoefficienten er:\n\n$k(n, r)=\\frac{n!}{r! \\cdot (n-r)!}$.\n\nDet svÃ¦re ved dette bevis, er ikke intuitionen eller argumentationen, det er regnereglerne og omskrivningerne vi fortager os som godt kan vÃ¦re lidt fremmede."},
      {
        "skridt": "r â‹… k(n, r) = r \\cdot \\frac{n!}{r! \\cdot (n-r)!} \\Leftrightarrow \\frac{n!}{(r - 1)! \\cdot (n - r)!}",
        "argumentation": "Vi fortager os en omskrivning og til at starte med sÃ¥ er det vigtigt vi forstÃ¥r hvad '$!$' betyder: \n\n$3! = 3 \\cdot 2 \\cdot 1$ \n\n$10! = 10 \\cdot 9 \\cdot 8 \\cdot ... \\cdot 1 $\n\n$n!=n \\cdot (n-1) \\cdot (n-2) \\cdot ... \\cdot1$ \n\n$n!=(n-1)!$ \n\nMed denne viden kan omskrivningen forklares ved at vi starter med at gange $r$ i tÃ¦lleren af brÃ¸ken: \n\n$\\frac{r \\cdot n!}{r! \\cdot (n-r)!}$ \n\nOg med vores forstÃ¥else af betydningen af '$!$' sÃ¥ kan vi slette $r$ fra tÃ¦lleren ved at omskrive $r!$: \n\n$r! = r \\cdot (r-1)!$ \n\nSÃ¥ vi har brÃ¸ken: \n\n$\\frac{\\cancel{r} \\cdot n!}{\\cancel{r}\\cdot(r-1)!\\cdot(n-r)!} \\Leftrightarrow \\frac{n!}{(r-1)!\\cdot(n-r)!}$"},
      {
        "skridt": "r â‹… k(n, r) = \\frac{n!}{(r - 1)! \\cdot (n - r)!}\\Leftrightarrow \\frac{n \\cdot (n - 1)!}{(r - 1)! \\cdot (n - r)!}",
        "argumentation": "Vi omskriver $n!$ til Med samme regel som tidligere: \n\n$n!=(n-1)!$ "},
      {
        "skridt": "r â‹… k(n, r) = n \\cdot \\frac{ (n - 1)!}{(r - 1)! \\cdot (n - r)!}",
        "argumentation": "Vi rykker ud foran brÃ¸ken, sÃ¥ vi har et stÃ¥ende udtryk for binomialkoefficienten, med Ã©n mindre succeser $r-1$ og Ã©n mindre forsÃ¸g, altsÃ¥ antalsparameter: $n-1$."},
      {
        "skridt": "r â‹… k(n, r) = n \\cdot \\frac{ (n - 1)!}{(r - 1)! \\cdot (n - r)!} = n \\cdot \\frac{ (n - 1)!}{(r - 1)! \\cdot ((n-1) - (r-1))!}",
        "argumentation": "Vi omskriver $(n-r)!$ fordi at sÃ¥ har vi bevist det og denne omskrivelse krÃ¦ver ikke nogen regne regler vi har lavet udtrykket om pÃ¥ denne mÃ¥de: \n\n$(n-r)! = ((n-1)-(r-1))!$ \n\n NÃ¥r vi sÃ¥ ophÃ¦ver den negative parentes der indeholder leddet med $r$ sÃ¥ skal vi Ã¦ndre fortegn\n\n$((n-1)-(r-1))! = (n-1-r+1)! = (n-r)!$"},
      {
        "skridt": "n \\cdot K(n - 1, r - 1)",
        "argumentation": "Dermed er ovenstÃ¥ende hjÃ¦lpesÃ¦tning bevist $\\blacksquare$."},
      {
        "skridt": "Bevis",
        "argumentation": "Nu beviser vi formlen for middelvÃ¦rdien, $\\mu$ (udtalt 'my'), til en binomialfordelt stokastisk variabel X med antalsparameter $n$ og sandsynlighedsparameter $p$."},
      {
        "skridt": "\\mu =x_0 \\cdot p_0 + x_1 \\cdot p_1 + \\cdots + x_n \\cdot p_n",
          "argumentation": "I fÃ¸rste skridt tager vi udgangspunkt i formlen for middelvÃ¦rdien af en diskret stokastisk variabel $X$, fordi en binomialfordeling netop er et eksempel pÃ¥ en diskret stokastisk variabel X. I en binomialfordeling er den stokastiske variabel $X$ defineret som antallet af succeser i $n$ uafhÃ¦ngige forsÃ¸g â€“ og da udfaldet af sÃ¥dan en variabel kun kan vÃ¦re heltal (f.eks. 0, 1, 2, ..., n), er $X$ per definition en diskret stokastisk variabel. Derfor giver det mening at starte med den generelle formel for middelvÃ¦rdi af diskrete stokastiske variabler nÃ¥r vi skal bevise formlen for middelvÃ¦rdi i en binomialfordeling. \n\nFormlen viser at middelvÃ¦rdien er summen af alle hÃ¦ndelser i vÃ¦rdimÃ¦ngden ganget med deres sandsynlighed."},
      {
        "skridt": "\\mu =\\sum_{r=0}^{n} x_r \\cdot p_r",
          "argumentation": "Vi sammentrÃ¦kker udtrykket ved sumtegnet."},
      {
        "skridt": "\\mu =\\sum_{r=0}^{n} r \\cdot p_r",
          "argumentation": "Vi Ã¦ndre notationen for $x_r$ til $r$ fordi at $x_r$ bare er antallet af succeser som i en binomialfordeling noteres med$r$."},
      {
        "skridt": "\\mu =\\sum_{r=1}^{n} r \\cdot p_r",
          "argumentation": "Vi Ã¦ndre 'r' i bunden af sumtegnet, fordi det tal der stÃ¥r dÃ©r i sumtegnet viser hvorfra summeringen starter og hvis den starter fra $r=0$ \nStarter den altsÃ¥ fra $0 \\cdot p_r$ og dette vil ikke have nogen effekt sÃ¥ det kan vi ligesÃ¥ godt Ã¦ndre"},
      {
        "skridt": "\\mu =\\sum_{r=01}^{n} r \\cdot P(X=r)",
          "argumentation": "Vi Ã¦ndre notationen for sandsynligheden til fra $p_r$ til notationen for formlen for sandsynligheden for at fÃ¥ $r$ succeser i $n$ forsÃ¸g i en binomial fordeling, som er noteret med $P(x=r)$."},
      {
        "skridt": "\\mu =\\sum_{r=1}^{n} r \\cdot K(n,r) \\cdot p^r \\cdot (1-p)^{n-r}",
          "argumentation": "Vi erstatter notationen med selve formlen"},
      {
        "skridt": "\\mu =\\sum_{r=1}^{n} n \\cdot K(n-1,r-1) \\cdot p^r \\cdot (1-p)^{n-r}",
          "argumentation": "Vi erstatter udtrykket for antallet af succeser $r$ ganget med binomialkoefficienten med udtrykket vi beviste i hjÃ¦lpesÃ¦tningen."},
      {
        "skridt": "\\mu = n \\cdot \\sum_{r=1}^{n} K(n-1,r-1) \\cdot p^r \\cdot (1-p)^{n-r}",
          "argumentation": "Vi rykker antalsparameteren $n$, som er en konstant ud fra sumtegnet. Det kan vi gÃ¸re fordi et sumtegn har den egenkab: \n\n$\\sum_{r=0}^{n} a \\cdot b_r = a \\cdot \\sum_{r=0}^{n} b_r$ \n\nAltsÃ¥ summen af et udtryk der er ganget med en konstant er lig med konstanten ganget med summen af udtrykket."},
      {
        "skridt": "\\mu = n \\cdot \\sum_{r=1}^{n} K(n-1,r-1) \\cdot p^r \\cdot (1-p)^{n-r} \\Leftrightarrow n \\cdot \\sum_{r=1}^{n} p \\cdot (K(n - 1, r - 1) \\cdot p^{r - 1} \\cdot (1 - p)^{n - r})",
          "argumentation": "Vi ved at formlen vi skal bevise indeholder sandsynlighedsparametern '$p$' og for at fremskaffe $p$p bruger vi denne potensregel: \n\n$a^r \\cdot a^s = a^{r+s}$ \n\nI udtrykket bruger vi det pÃ¥ denne mÃ¥de til at Ã¦ndre $p^r$ uden at Ã¦ndre nogen matematisk betydning: \n\n$p^1 \\cdot p^{r-1} = p \\cdot p^{r-1} = p^{r-1 + 1} = p^r$ \n\nSÃ¥ udtrykket ser nu sÃ¥dan her ud: \n\n$n \\cdot \\sum_{r=1}^{n} K(n,r) \\cdot p \\cdot p^{r-1} \\cdot (1-p)^{n-r}$ \n\nOg dette kan omskrives til:\n\n$n \\cdot \\sum_{r=1}^{n} p \\cdot (K(n,r) \\cdot p^{r-1} \\cdot (1-p)^{n-r})$ \n\nParentesen er alene af Â´pÃ¦dagogisk' grund da den viser at 'p' bliver adskilt fra resten af udtrykket der er en del af sumtegnet, sÃ¥ at vi kan rykke 'p' ud foran sumtegnet."},
      {
        "skridt": "\\mu = n \\cdot p \\cdot \\sum_{r=1}^{n} (K(n - 1, r - 1) \\cdot p^{r - 1} \\cdot (1 - p)^{n - r})",
          "argumentation": "Nu rykker vi $p$ ud foran sumtegnet."},
      {
        "skridt": "\\mu = n \\cdot p \\cdot \\sum_{r=1}^{m} (K(m, l) \\cdot p^l \\cdot (1 - p)^{m - l})",
          "argumentation": "Nu Ã¦ndre vi notationen i sumtegnet med disse udtryk: \n\n$m=n-1$\n\n$l = r-1$ \n\nDet er fordi at sÃ¥ har vi faktisk lavet en ny binomialfordeling, med antalsparameter $m$, sandsynlighedsparameter $p$ og hvor antal successer er noteret med $l$. Det er en fordel, at vi nu har omskrevet udtrykket til at indeholde en fuld binomialfordeling, fordi vi ved, at summen af sandsynlighederne for alle mulige udfald i en sandsynlighedsfordeling â€“ og dermed ogsÃ¥ en binomialfordeling â€“ altid er lig 1. Det skyldes, at en sandsynlighedsfordeling netop beskriver alle de mÃ¥der, en stokastisk variabel kan opfÃ¸re sig pÃ¥, og summen af sandsynlighederne for alle disse udfald mÃ¥ nÃ¸dvendigvis dÃ¦kke hele udfaldsrummet, altsÃ¥ $100%$."},
      {
        "skridt": "\\mu = n \\cdot p \\cdot \\sum_{r=1}^{m} (K(m, l) \\cdot p^l \\cdot (1 - p)^{m - l}) \\Leftrightarrow \\mu = n \\cdot p \\cdot 1 \\Leftrightarrow \\mu = n \\cdot p",
          "argumentation": "NÃ¥r summen derfor prÃ¦cist svarer til en komplet binomialfordeling, kan vi erstatte hele summen med 1, hvilket i sidste trin i beviset reducerer udtrykket."},
      {
        "skridt": "\\mu = n \\cdot p",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
        ]
      },
    {
      "bevis": "5) Differentialkvotienten til en vektorfunktion",
      "sÃ¦tning": "SÃ¦tning: Hvis de reelle koordinatfunktioner ğ’™(ğ’•) og ğ’š(ğ’•) er differentiable i ğ’•ğŸ er vektorfunktionen \n$\\vec{s}(t) = \\begin{pmatrix} x(t) \\\\ y(t) \\end{pmatrix}$ differentiabel i ğ’•ğŸ med differentialkvotienten \n$\\vec{s}'(t_0) = \\begin{pmatrix} x'(t_0) \\\\ y'(t_0) \\end{pmatrix}$",
      "udfÃ¸relse": [
        {
          "skridt": "\\Delta t = (t_0 + h) - t_0 = h",
          "argumentation": "Som sÃ¦tningen fortÃ¦ller os sÃ¥ baserer vi beviset pÃ¥ forudsÃ¦tningen om at de reelle funktioner $x(t)$ og $y(t)$ er differentiable i punktet $t_0$. Reelle funktioner er funktioner hvor at der mÃ¥ hÃ¸jst vÃ¦re Ã©n y-vÃ¦rdi til hver vÃ¦rdi i definitionsmÃ¦ngden. MÃ¥let med beviset er at bevise hvis en vektorfunktion $s(t)$ bestÃ¥r af to relle funktioner $x(t)$ og $y(t)$ som begge er differentiable i $t_0$ sÃ¥ er funktionen $s(t)$ differentiabel ved $t_0$ med: \n\n $\\vec{s}'(t) = \\begin{pmatrix} x'(t_0) \\\\ y'(t_0) \\end{pmatrix}$. \n\nVi beviser at $x(t)$ og $y(t)$ er differentiable i $t_0$ med tretrinsreglen: \n\n1. Bestem differenskvotienten \n2. Omskriv differenskvotienten \n3. UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvotienten. \n\nDet fÃ¸rste skridt i tretrinsreglen er som sagt at bestemme differenskvotienten, og vi har to funktioner $x(t)$ og $y(t)$ som vi skal bestemme differenskvotienten for hver isÃ¦r. \n Differenskvotienten for $x(t)$ er hÃ¦ldningen af sekanten (linje der gÃ¥r gennem to punkter) der gÃ¥r gennem punkterne: \n$(t_0 , x(t_0))$ og $(t_0 + h , x(t_0 + h))$ \n\nOg differenskvotienten for $y(x)$ er hÃ¦ldningen af sekanten der gÃ¥r gennem punkterne:\n$(t_0 , y(t_0))$ og $(t_0 + h , y(t_0 + h))$ \n\nNÃ¥r vi skal bestemme differenskvotienten, gÃ¸r vi brug af to-punkts-formlen der bestemmer hÃ¦ldningen 'a' pÃ¥ en linje der gÃ¥r gennem to punkter: \n\n$a = \\frac{y_2 - y_1}{x_2 - x_1}$ \n\nFormlen bestemmer hÃ¦ldningen for en linje der gÃ¥r gennem 2 vilkÃ¥rlige punkter: $(x_1 , y_1)$ og $(x_2 , y_2)$ ved at dividere de to punkters forskel i funktionsvÃ¦rdi med de to punkters forskel i x-vÃ¦rdi. \n\nHvis vi anvender formlen pÃ¥ vores to funktioner \n$x(t)$ i punkterne $(t_0 , x(t_0))$ og $(t_0 + h , x(t_0 + h))$ \n$y(t)$ i punkterne $(t_0 , y(t_0))$ og $(t_0 + h , y(t_0 + h))$ , \n\nSÃ¥ betyder det at vi kan bestemme deres differenskvotienter med disse brÃ¸ker: \n\n$\\frac{x(t_0 + h) - x(t_0)}{(t_0 + h) - t_0}$ \n\n$\\frac{y(t_0 + h) - y(t_0)}{(t_0 + h) - t_0}$ \n\nFÃ¸rste skridt i beviset er altsÃ¥ at opnÃ¥ disse to udtryk fordi at de er hver isÃ¦r differenskvotienterne for $x(t)$ og $y(t)$ . \n\nDerfor starter beviset med at reducerer udtrykket for forskellen i t-vÃ¦rdi ($\\Delta t$) mellem de to punkter, til 'h'"},
        {
          "skridt": "\\Delta \\vec{s} = \\vec{s}(t_0 + h) - \\vec{s}(t_0)",
          "argumentation": "Som formlen viser skal vi ogsÃ¥ bruge forskellen i funktionsvÃ¦rdier, $\\Delta \\vec{s}$, til at bestemme differenskvotienten. \nDet gÃ¸res ved at trÃ¦kke de to funktionsvÃ¦rdier  $s(t_0 + h)$ og $s(t_0)$ fra hinanden"},
        {
          "skridt": "\\frac{\\Delta \\vec{s}}{h} = \\frac{\\vec{s}(t_0 + h) - \\vec{s}(t_0)}{h}",
          "argumentation": "Nu tager vi fat i formlen for differenskvotienten of indsÃ¦tter vi vores udtryk for forskellen i funktionsvÃ¦rdier for $s(t)$ og erstatter $\\Delta t$ med 'h' som var det vi bestemte $\\Delta t$ til at vÃ¦re i fÃ¸rste skridt"},
        {
          "skridt": "\\frac{\\Delta \\vec{s}}{h} = \\frac{1}{h} \\cdot (\\vec{s}(t_0 + h) - \\vec{s}(t_0))",
          "argumentation": "Nu rykker vi $\\frac{1}{h}$ ud fra differenskvotient brÃ¸ken og vÃ¦k fra $\\vec{s}(t)$ for at kunne omskrive udtrykket ved at indsÃ¦tte funktionsforskriften for $\\vec{s}(t)$ som er givet i bevissÃ¦tningen og der efter gange brÃ¸ken $\\frac{1}{h}$ som en konstant pÃ¥ vektoren."},
        {
          "skridt": "\\frac{\\Delta \\vec{s}}{h} = \\frac{1}{h} \\cdot \\left(\\begin{pmatrix} x(t_0 + h) \\\\ y(t_0 + h) \\end{pmatrix} - \\begin{pmatrix} x(t_0) \\\\ y(t_0) \\end{pmatrix} \\right) = \\frac{\\Delta \\vec{s}}{h} = \\frac{1}{h} \\cdot \\begin{pmatrix} x(t_0 + h) - x(t_0) \\\\ y(t_0 + h) - y(t_0) \\end{pmatrix}",
          "argumentation": "Vi indsÃ¦tter funktionsforskriften for $\\vec{s}(t)$ som er givet i bevissÃ¦tningen, husk at anvend de to t-vÃ¦rdier for de to forskellige punkter som input til $x(t)$ og $y(t)$"},
        {
          "skridt": "\\frac{\\Delta \\vec{s}}{h} = \\frac{\\Delta \\vec{s}}{h} = \\frac{1}{h} \\cdot \\begin{pmatrix} x(t_0 + h) - x(t_0) \\\\ y(t_0 + h) - y(t_0) \\end{pmatrix} = \\begin{pmatrix} \\frac{x(t_0 + h) - x(t_0)}{h} \\\\ \\frac{y(t_0 + h) - y(t_0)}{h} \\end{pmatrix}",
          "argumentation": "Vi ganger konstanten som er en brÃ¸k der bestÃ¥r af $1$ divideret med forskel i t-vÃ¦rdi ind i vektoren med reglen: \n\n$a \\cdot \\begin{pmatrix} b \\\\ c \\end{pmatrix} = \\begin{pmatrix} a \\cdot b \\\\ a \\cdot c \\end{pmatrix}$"},
        {
          "skridt": "\\frac{\\Delta \\vec{s}}{h} = \\begin{pmatrix} \\frac{x(t_0 + h) - x(t_0)}{h} \\\\ \\frac{y(t_0 + h) - y(t_0)}{h} \\end{pmatrix}",
          "argumentation": "Nu har vi bestemt og omskrevet differenskvotienten for $\\vec{s}(t)$ til at indeholde differenskvotienterne for $x(t)$ og $y(t)$ og derfor kan vi gÃ¥ til sidste skridt af tretrinsreglen og anvende $\\lim_{h \\to 0}$ pÃ¥ $\\vec{s}(t)$"},
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta \\vec{s}}{h} = \\lim_{h \\to 0} \\begin{pmatrix} \\frac{x(t_0 + h) - x(t_0)}{h} \\\\ \\frac{y(t_0 + h) - y(t_0)}{h} \\end{pmatrix}",
          "argumentation": "Nu anvender vi $\\lim_{h \\to 0}$ pÃ¥ differenskvotienten for $\\vec{s}(t)$"},
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta \\vec{s}}{h} = \\lim_{h \\to 0} \\begin{pmatrix} \\frac{x(t_0 + h) - x(t_0)}{h} \\\\ \\frac{y(t_0 + h) - y(t_0)}{h} \\end{pmatrix} = \\begin{pmatrix} x'(t_0) \\\\ y'(t_0) \\end{pmatrix}",
          "argumentation": "Vi har anvendt $\\lim_{h \\to 0}$ pÃ¥ differenskvotienten for $\\vec{s}(t)$ fordi at vi vidste hvad grÃ¦nsevÃ¦rdierne for det omskrevet udtryk var sÃ¥ har vi nu bestemt differentialkvotienten for $\\vec{s}(t)$"},
        {
          "skridt": "\\vec{s}'(t) = \\begin{pmatrix} x'(t_0) \\\\ y'(t_0) \\end{pmatrix}",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
    ]
    },
    {
      "bevis": "6) Bevis Tangentplan",
      "sÃ¦tning": "Lad ğ’‡(ğ’™, ğ’š) vÃ¦re en funktion af to variable, og lad punktet ğ‘·(ğ’™ğŸ, ğ’šğŸ, ğ’›ğŸ) vÃ¦re et punkt pÃ¥ grafen for ğ’‡(ğ’™, ğ’š). \n\n Tangentplanen for ğ’‡(ğ’™, ğ’š) i punktet ğ‘· er givet ved ligningen: \n\nğ’› = $f_x$â€²(ğ’™ğŸ, ğ’šğŸ)(ğ’™ âˆ’ ğ’™ğŸ) + $f_y$'(ğ’™ğŸ, ğ’šğŸ)(ğ’š âˆ’ ğ’šğŸ) + ğ’‡(ğ’™ğŸ, ğ’šğŸ)",
      "udfÃ¸relse": [
        {
          "skridt": "Introduktion",
          "argumentation": "Vi skal bevise at tangentplanen til en funktion $f(x,y)$ i punktet $(x_0, y_0, z_0)$ har ligningen: \n\n$z= f_{x}'(x_0, y_0)\\cdot(x-x_0)+f_{y}'(x_0, y_0)\\cdot(y-y_0)+f(x_0, y_0)$\n\nVi er ogsÃ¥ givet noget information pÃ¥ fÃ¸rste side af kompendiet omkring nogle definitioner og forudsÃ¦tninger som vi kan gÃ¸re brug af til beviset. For det fÃ¸rste fÃ¥r vi at vide at et tangentplan i punktet $(x_0, y_0, z_0)$ kan beskrives med fÃ¸lgende ligning:\n\n$0=a(x-x_0) + b(y-y_0) + c(z-z_0)$ \n\nHvor at vi ogsÃ¥ fÃ¥r at vide at $a$, $b$ og $c$ udgÃ¸r normalvektoren til tangentplanet: \n\n$\\vec{n} = \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix}$  \n\nDet vil altsÃ¥ sige at denne vektor stÃ¥r vinkelret pÃ¥ tangentplanen og at den som vÃ¦re ortorgonal med alle vektore der fÃ¸lger tangentplanet. \n\nVi fÃ¥r ogsÃ¥ at vide at ortogonale vektore med 3 dimensioner er defineret ved at prikproduktet af dem er lig 0. Eksempel pÃ¥ to ortogonale vektore $\\vec{a}$ og $\\vec{b}$: \n\n$\\vec{a} = \\begin{pmatrix} a_1 \\\\ a_2 \\\\ a_1 \\end{pmatrix}$ \n\n$\\vec{b} = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ b_1 \\end{pmatrix}$ \n\nDisse to vektore er ortorgonale hvis prikproduktet giver $0$:\n\n$\\vec{a} \\cdot \\vec{b} = a_1 \\cdot b_1 + a_2 \\cdot b_2 + a_3 \\cdot b_3 = 0$"},
        {
          "skridt": "\\begin{align*} a_x &= f'_x(x_0, y_0) \\\\ a_y &= f'_y(x_0, y_0) \\end{align*}",
          "argumentation": "Vi starter med at definere variabelnavne for de partielt afledte af $f(x,y)$ i punktet $(x_0, y_0)$. \n\nDet vi har gjort er at vi har defineret to variabler, hvor den ene kaldes $a_x$, som er lig den partielt afledte af $f(x,y)$ i punktet $(x_0, y_0, z_0)$ med hensyn til $x$. Dette betyder at denne variabel beskriver hÃ¦ldningen af tangentplanet i punktet $(x_0, y_0, z_0)$ i retning af $x$-aksen. Med andre ord kan man ogsÃ¥ sige at denne variabel fortÃ¦ller os hvor meget $z$ Ã¦ndre sig med nÃ¥r $x$ Ã¦ndre sig i punktet $(x_0, y_0, z_0)$. \n\nDen anden variabel $a_y$ er lig den partielt afledte af $f(x,y)$ i punkt og gÃ¸r de samme ting som $a_x$ bare med hensyn til Ã¦ndring i $z$ i forhold til Ã¦ndring i $y$-aksen."},
        {
          "skridt": "\\vec{v} = \\begin{pmatrix} 1 \\\\ 0 \\\\ a_x \\end{pmatrix} \\vec{w} = \\begin{pmatrix} 0 \\\\ 1 \\\\ a_y \\end{pmatrix}",
          "argumentation": "Nu definerer vi to vektore fordi som sagt er vi jo givet en beskrivelse for en ligning der beskriver et tangentplan, og det er godt sted at starte at bruge det vi ved og sÃ¥ kan det vÃ¦re at vi kan begynde at rykke rundt pÃ¥ den. \n\nSom sagt sÃ¥ er det denne ligning vi starter beviset med at lave\n\n$0=a(x-x_0) + b(y-y_0) + c(z-z_0)$ \n\nHvor at $a$, $b$ og $c$ udgÃ¸r normalvektoren til tangentplanet. Derfor laver vi en vektor $\\vec{v}$ der er parallel med x-aksen og viser hvor meget $z$ Ã¦ndrer sig nÃ¥r man bevÃ¦ger sig $1$ hen af x-aksen, vektoren beskriver altsÃ¥ hÃ¦ldningen i $xz$-planet. Vi laver os en vektor $\\vec{w}$ der er parallel med y-aksen og viser hvor meget $z$ Ã¦ndrer sig nÃ¥r man bevÃ¦ger sig $1$ hen af y-aksen, vektoren beskriver altsÃ¥ hÃ¦ldningen i $yz$-planet. \n\nSÃ¥ siden de her to vektore beskriver begge hÃ¦ldninger i tangentplanet, sÃ¥ skal normalvektoren til tangentplanet vÃ¦re ortogonal med begge vektore."},
        {
          "skridt": "\\begin{align*} \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ 0 \\\\ a_x \\end{pmatrix} &= 0 \\\\ \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ 1 \\\\ a_y \\end{pmatrix} &= 0 \\end{align*}",
          "argumentation": "Nu skal vi bestemme normalvektoren til tangentplanet for at kunne opstille den ligning som vi ved gÃ¦lder. \n\nVi ved at normalvektoren til tangentplanet er ortogonal med vektoren $\\vec{v}$ og vektoren $\\vec{w}$ og det betyder at prikproduktet skal vÃ¦re lig 0. Med denne viden kan vi lave et ligningssystem med brug af reglen til hvordan man bestemmer prikrpoduktet af vektore med 3 dimensioner: \n\n$\\vec{a} \\cdot \\vec{b} = a_1 \\cdot b_1 + a_2 \\cdot b_2 + a_3 \\cdot b_3$"},
        {
          "skridt": "\\begin{align*} a \\cdot 1 + b \\cdot 0 + c \\cdot a_x &= 0 \\\\ a + c a_x &= 0 \\\\ a &= - c a_x \\tag{1} \\\\ \\\\ a \\cdot 0 + b \\cdot 1 + c \\cdot a_y &= 0 \\\\ b + c a_y &= 0 \\\\ a &= - c a_y\\tag{2} \\end{align*}",
          "argumentation": "Vi Ã¦ndre beskrivelserne for ligningssystemet ved at anvende formlen for skalarproduktet af to vektore med 3 dimensioner. Vi kan ogsÃ¥ hurtigt reducere os frem til udtryk for bÃ¥de $a$ og $b$ vÃ¦rdierne i normalvektoren ved at isolere dem i hver af de to ligninger."},
        {
          "skridt": "\\vec{n} = \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} = \\begin{pmatrix} -c a_x \\\\ -c a_y \\\\ c \\end{pmatrix}",
          "argumentation": "Okay efter vores reducering af ligningssystemet har vi nu beskrivelser for vÃ¦rdierne $a$ og $b$ i normalvektoren, men vi kender jo stadig ikke $c$?. \n\nMen faktisk sÃ¥ kan vi godt bestemme $c$, fordi at normalvektore har den egenskab at de stadig er normalvektore uagtet af hvad lÃ¦ngden er pÃ¥ dem sÃ¥ lÃ¦nge den ikke er 0. \nDet vil sige at en normalvektor $\\vec{n}$ er ogsÃ¥ en normalvektor hvis den bliver ganget med en konstant $k$, hvor $k$ ikke er 0. Eftersom alle vÃ¦rdier i den normalvektor vi har reduceret os frem til er ganget med $c$ som jo ogsÃ¥ er en konstant sÃ¥ er det stadig en normalvektor hvis den ikke bliver ganget med $c$. SÃ¥ lÃ¦nge at vi fjerne $c$ for alle vÃ¦rdierne. \n\n$\\vec{n} = \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} = \\begin{pmatrix} -c\\cdot a_x \\\\ -c \\cdot a_y \\\\ c \\cdot 1 \\end{pmatrix}$ \n\n$\\vec{n} = \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} = c\\cdot \\begin{pmatrix} - a_x \\\\ - a_y \\\\ 1 \\end{pmatrix} \\Leftrightarrow \\begin{pmatrix} - a_x \\\\ - a_y \\\\ 1 \\end{pmatrix}$"},
        {
          "skridt": "\\vec{n} = \\begin{pmatrix} - a_x \\\\ - a_y \\\\ 1 \\end{pmatrix}",
          "argumentation": "Nu har vi defineret normalvektoren til tangentplanet og vi kan nu indsÃ¦tte den i den ligning vi er givet i starten til at beskrive tangentplanet."},
        {
          "skridt": "0 = a(x - x_0) + b(y - y_0) + c(z - z_0) \\Leftrightarrow 0 = -a_x(x - x_0) - a_y(y - y_0) + 1(z - z_0)",
          "argumentation": "Nu IndsÃ¦tter vi vores vÃ¦rdier for $a$, $b$ og $c$ i den ligning vi er givet i starten til at beskrive tangentplanet."},
        {
          "skridt": "0  = -a_x(x - x_0) - a_y(y - y_0) + (z - z_0) \\Leftrightarrow 0  = -a_x(x - x_0) - a_y(y - y_0) + z - z_0",
          "argumentation": "Vi ganger parentesen ud og ophÃ¦ver den sidste parentes"},
        {
          "skridt": " a_x(x - x_0) + a_y(y - y_0) + z_0 = z ",
          "argumentation": "Vi rykker alle andre led end $+z$ over pÃ¥ venstre side af lighedstegnet og Ã¦ndre fortegn, sÃ¥ vi kan isolere $z$"},
        {
          "skridt": "z =  a_x(x - x_0) + a_y(y - y_0) + z_0 \\Leftrightarrow z =  f_x'(x_0, y_0)(x - x_0) + f_y'(x_0, y_0)(y - y_0) + f(x_0, y_0)",
          "argumentation": "Vi bytter rundt pÃ¥ lighedstegner for at det ser ordentligt ud ogsÃ¥ erstatter vi $a_x$, $a_y$ og $z_0$ med deres matematiske definitioner."},
        {
          "skridt": "z = f_x'(x_0, y_0)(x - x_0) + f_y'(x_0, y_0)(y - y_0) + f(x_0, y_0)",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    },
    {
      "bevis": "7) Bevis for differentialkvotienten for 1/x",
      "sÃ¦tning": "SÃ¦tning: \n$f(x) = \\frac{1}{x}$,  hvor $x \\cancel{=} 0$, er differentiabel i $x_0$, med differentialkvotienten $f'(x_0) = -\\frac{1}{x_0^2}$",
      "udfÃ¸relse": [
        {
          "skridt": "\\Delta x = (x_0 + h) - x_0 = h",
          "argumentation": "Det er et bevis for en differentialkvotient, sÃ¥ vi skal fÃ¸lge tretrinsreglen: \n\n1. Bestem differenskvotienten \n2. Omskriv differenskvotienten \n3. UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi og i sÃ¥ fald bestem differentialkvotienten. \n\nDet fÃ¸rste skridt i tretrinsreglen er som sagt at bestemme differenskvotienten, og det betyder at vi skal bestemme hÃ¦ldningen af sekanten der gÃ¥r gennem punkterne: \n$(x_0 , f(x_0))$ og $(x_0 + h , f(x_0 + h))$ \n\nSÃ¥ derfor skal vi bestemme forskellen i x-vÃ¦rdi mellem de to punkter, og det gÃ¸r vi ved at trÃ¦kke $x_0$ fra $x_0 + h$ og vi fÃ¥r 'h'."},
        {
          "skridt": "\\Delta y = f(x_0 + h) - f(x_0)",
          "argumentation": "Vi bestemmer forskellen i funktionsvÃ¦rdi, $\\Delta y$, for $f(x)$ i punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$"},
        {
          "skridt": " \\Delta y = \\frac{1}{x_0 + h} - \\frac{1}{x_0}",
          "argumentation": "Vi indsÃ¦tter funktionsforskriften for $f(x)$ og vi har nu et udtryk for forskellen i funktionsvÃ¦rdi for $f(x)$ i punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$"},
        {
          "skridt": " \\Delta y = \\frac{1}{x_0 + h} - \\frac{1}{x_0} = \\frac{x_0}{x_0 \\cdot (x_0 + h)} - \\frac{1 \\cdot (x_0 + h)}{x_0 \\cdot (x_0 + h)}",
          "argumentation": "Vi anvender reglen der gÃ¸r at to brÃ¸ker med forskellige nÃ¦vnere kan blive trukket fra hinanden: \n\n$\\frac{a}{b} - \\frac{c}{d} = \\frac{a \\cdot d}{b \\cdot d} - \\frac{c \\cdot b}{d \\cdot b} = \\frac{a \\cdot d - c \\cdot b}{b \\cdot d} $\n\nFordi sÃ¥ kan vi reducere udtrykket for forskel i funktionsvÃ¦rdi"},
        {
          "skridt": "\\Delta y = \\frac{x_0 - (x_0 + h)}{x_0 \\cdot (x_0 + h)} \\Leftrightarrow \\Delta y = \\frac{-h}{x_0(x_0 + h)}",
          "argumentation": "Vi reducere udtrykket for forskel i funktionsvÃ¦rdi"},
        {
          "skridt": "\\frac{\\Delta y}{\\Delta x} = \\frac{\\Delta y}{h} = \\frac{f(x_0 + h) - f(x_0)}{h}",
          "argumentation": "Med vores reducering kan vi nu opstille udtrykket for differenskvotienten af $f(x_0)$."},
        {
          "skridt": "\\frac{\\Delta y}{h} =\\frac{\\frac{-h}{x_0(x_0 + h)}}{h}",
          "argumentation": "Nu indsÃ¦tter vi det reducerede udtryk for forskel i funktionsvÃ¦rdi for $f(x)$ i punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$ \n\nOg dermed har vi klaret trin 1 med at bestemme differenskvotienten for $f(x)$ sÃ¥ nu skal vi omskrive den sÃ¥ vi kan bestemme grÃ¦nsevÃ¦rdierne og dermed differentialkvotienten."},
        {
          "skridt": "\\frac{\\Delta y}{h} =\\frac{\\frac{-h}{x_0(x_0 + h)}}{h} \\Leftrightarrow \\frac{\\Delta y}{h} = \\frac{-1}{x_0(x_0 + h)}",
          "argumentation": "Vi omskriver brÃ¸ken med reglen: \n\n$\\frac{a}{\\frac{b}{c}} = \\frac{a}{b \\cdot c} $\n\nNÃ¥r vi anvender den pÃ¥ udtrykket: \n\n$\\frac{-h}{\\frac{x_0(x_0 + h)}{h}} = \\frac{- h}{x_0(x_0 + h) \\cdot h} = \\frac{-1 \\cancel{\\cdot h}}{x_0(x_0 + h) \\cancel{\\cdot h}}$"},
        {
          "skridt": "\\frac{\\Delta y}{h} = -\\frac{1}{x_0(x_0 + h)}",
          "argumentation": "Nu er differenskvotienten omskrevet til et udtryk hvor vi kan bestemme grÃ¦nsevÃ¦rdien fordi at $h$ bliver gjort lille uden at vi risikere at brÃ¸ken fÃ¥r en nÃ¦vner der er lig 0."},
            {
              "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\lim_{h \\to 0} ( \\frac{-1}{x_0(x_0 + h)}) = - \\left( \\frac{1}{x_0(x_0 + 0)} \\right)",
        "argumentation": "Nu bestemmer vi grÃ¦nsevÃ¦rdien for udtrykket med $\\lim_{h \\to 0}$"},
            {
              "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\frac{-1}{x_0 \\cdot x_0} = - \\frac{1}{x_0^2} ",
        "argumentation": "Vi reducerer udtrykekt"},
            {
              "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = - \\frac{1}{x_0^2} \\Leftrightarrow f'(x_0) = - \\frac{1}{x_0^2}",
        "argumentation": "Nu har vi succesfuldt fundet grÃ¦nsevÃ¦rdien og kan Ã¦ndre $\\lim_{h \\to 0} \\frac{\\Delta y}{h}$ til differentialkvotienten for $f(x)$ i punktet $x_0$."},
            {
              "skridt": "f'(x_0) = - \\frac{1}{x_0^2}",
        "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    },
    {
      "bevis": "7) Bevis for differentialkvotienten for x^2",
      "sÃ¦tning": "SÃ¦tning: \n$f(x) = x^2$, er differentiabel i $x_0$, med differentialkvotienten $f'(x_0) = 2x_0$",
      "udfÃ¸relse": [
        {
          "skridt": "\\Delta x = (x_0 + h) - x_0 = h",
          "argumentation": "Det er et bevis for en differentialkvotient, sÃ¥ vi skal fÃ¸lge tretrinsreglen: \n\n1. Bestem differenskvotienten \n2. Omskriv differenskvotienten \n3. UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi og i sÃ¥ fald bestem differentialkvotienten. \n\nDet fÃ¸rste skridt i tretrinsreglen er som sagt at bestemme differenskvotienten, og det betyder at vi skal bestemme hÃ¦ldningen af sekanten der gÃ¥r gennem punkterne: \n$(x_0 , f(x_0))$ og $(x_0 + h , f(x_0 + h))$ \n\nSÃ¥ derfor skal vi bestemme forskellen i x-vÃ¦rdi mellem de to punkter, og det gÃ¸r vi ved at trÃ¦kke $x_0$ fra $x_0 + h$ og vi fÃ¥r 'h'."},
        {
          "skridt": "\\Delta y = f(x_0 + h) - f(x_0)",
          "argumentation": "Vi bestemmer forskellen i funktionsvÃ¦rdi, $\\Delta y$, for $f(x)$ i punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$"},
        {
          "skridt": " \\Delta y = (x_0 + h)^2 - (x_0)^2",
          "argumentation": "Vi indsÃ¦tter funktionsforskriften for $f(x)$ og vi har nu et udtryk for forskellen i funktionsvÃ¦rdi for $f(x)$ i punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$"},
        {
          "skridt": " \\Delta y = (x_0 + h)^2 - (x_0)^2 \\Leftrightarrow \\Delta y = x_0^2 + 2x_0 h + h^2 - x_0^2",
          "argumentation": "Vi ophÃ¦ver parenteserne ved at gange dem ud. \n\nDen ene har form som den fÃ¸rste kvadratsÃ¦tning, der har denne udregning: \n\n$(a+b)^2 = a^2 + b^2 + 2ab$"},
        {
          "skridt": "\\Delta y = 2x_0 h + h^2",
          "argumentation": "Vi reducere udtrykket for forskel i funktionsvÃ¦rdi sÃ¥ meget som muligt"},
        {
          "skridt": "\\frac{\\Delta y}{\\Delta x} = \\frac{\\Delta y}{h} = \\frac{f(x_0 + h) - f(x_0)}{h}",
          "argumentation": "Med vores reducering kan vi nu opstille udtrykket for differenskvotienten af $f(x_0)$."},
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{2x_0 h + h^2}{h}",
          "argumentation": "Nu indsÃ¦tter vi det reducerede udtryk for forskel i funktionsvÃ¦rdi for $f(x)$ i punkterne $(x_0, f(x_0))$ og $(x_0+h, f(x_0+h))$ \n\nOg dermed har vi klaret trin 1 med at bestemme differenskvotienten for $f(x)$ sÃ¥ nu skal vi omskrive den sÃ¥ vi kan bestemme grÃ¦nsevÃ¦rdierne og dermed differentialkvotienten."},
        {
          "skridt": "\\frac{\\Delta y}{h} = \\frac{2x_0 h + h^2}{h} = \\frac{2x_0 \\cdot \\cancel{h} + h \\cdot \\cancel{h}}{\\cancel{h}} = 2x_0 + h",
          "argumentation": "Vi omskriver og reducere brÃ¸ken fordi at der bliver ganget med '$h$' i nÃ¦vneren og der optrÃ¦der et '$h$' i hvert led i tÃ¦lleren. Derfor kan vi slette Ã©t '$h$' fra hvert led i tÃ¦lleren og dermed ogsÃ¥ '$h$' fra nÃ¦vneren."},
        {
          "skridt": "\\frac{\\Delta y}{h} = 2x_0 + h",
          "argumentation": "Trin 2 er nu klaret fordi at vi har nu omskrevet differenskvotienten til et udtryk hvor vi kan bestemme grÃ¦nsevÃ¦rdien."},
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\lim_{h \\to 0} (2x_0 + h)",
          "argumentation": "Vi bestemmer grÃ¦nsevÃ¦rdien af differenskvotienten ved at anvende $\\lim_{h \\to 0}$"},
        {
          "skridt": "\\lim_{h \\to 0} \\frac{\\Delta y}{h} = \\lim_{h \\to 0} (2x_0 + 0) \\Leftrightarrow \\lim_{h \\to 0} \\frac{\\Delta y}{h} = 2x_0",
          "argumentation": "Vi har succesfuldt bestemt grÃ¦nsevÃ¦rdien for differenskvotienten og kan derfor Ã¦ndre $\\lim_{h \\to 0} \\frac{\\Delta y}{h}$ til differentialkvotienten for $f(x)$ i punktet $x_0$."},
        {
          "skridt": "f'(x_0) = 2x_0",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    },
    {
      "bevis": "8/9) Differentialligningsbevis: Logistisk vÃ¦kst",
      "sÃ¦tning": "Differentialligningen $y' = y(b - ay), \\quad a, b \\ne 0$ \n\nHar de ikke-trivielle lÃ¸sninger: $y(x) = \\frac{\\frac{b}{a}}{1 + c e^{-bx}}, \\quad$ hvor c er et tal.",
      "udfÃ¸relse": [
        {
          "skridt": "z=z(x)=\\frac{1}{y(x)}",
          "argumentation": "Vi begynder beviset med at lave en 'hjÃ¦lpefunktion', $z(x)$, som er en sammensat funktion der har den originale funktion, $y(x)$, som indre funktion. \n$y(x)$ er den funktion hvis generelle form er den generelle lÃ¸sning til den givet differentialligning.\nDet er $y(x)$'s generelle form, som vi skal finde ud fra differentialligningen og beviset gÃ¥r ud pÃ¥ at vi skal bevise den metode der er til dÃ©t formÃ¥l. \n\nEftersom vi skal bevise en lÃ¸sning til differentialligninger, der har denne ikke-lineÃ¦re form, skal vi tage denne 'omvej' til formÃ¥l for at lave en differentialligning af hvor vi kender dens lÃ¸sning. \n\nMÃ¥let med hjÃ¦lpefunktionen er aflede den, for at ende med en differentialligning (der beskriver den afledte af hjÃ¦lperfunktionen), der har en form hvor vi kender lÃ¸sningen. NÃ¥r vi sÃ¥ bestemmer lÃ¸sningen til differentialligningen for hjÃ¦lperfunktionen, sÃ¥ har vi jo bestemt en funktionsforskrift for hjÃ¦lpefunktionen som jo er en sammensat funktion med vores originale funktion, $y(x)$, som indre funktion. Efter det kan vi isolere den originale funktion og bestemme dens funktionsforskrift. \n\nSÃ¥ vi starter altsÃ¥ med at lave en sammensat funktion med den funktion vi ikke kender formen af, for sÃ¥ at aflede funktionen hvor vi kan anvende vores viden om dens afledte. \nOg nÃ¥r vi sÃ¥ har gjort det kan vi lÃ¸se denne differentialligning for hjÃ¦lpefunktionen og derefter isolere den originale funktion fra."},
        {
          "skridt": "z' = -\\frac{1}{y^2} \\cdot y'",
          "argumentation": "Vi afleder hjÃ¦lpefunktionen, $z(x)$, som er en sammensat funktion og derfor bruges kÃ¦dereglen:\n\n$(f(g(x)))' = f'(g(x)) \\cdot g'(x)$ \n\nKÃ¦dereglen har i Ã¸vrigt ogsÃ¥ den gode egenskab at den siger at man skal aflede den indre funktion, som i vores tilfÃ¦lde jo er den afledte af $y(x)$. \nVi kender jo en betegnelse for den afledte af $y(x)$ fordi det er differentialligningen som vi i beviset skal bevise en lÃ¸sning til."},
        {
          "skridt": "z' = -\\frac{1}{y^2} \\cdot y(b - ay)",
          "argumentation": "Vi indsÃ¦tter betegnelsen for $y'$, som vi kender fra differentialligningen i bevissÃ¦tningen, ind pÃ¥ $y'$'s plads i udtrykket for $z'$"},
        {
          "skridt": "z' = -\\frac{1}{y} (b - ay)",
          "argumentation": "Der er Ã©t led i tÃ¦lleren som ganges med $y$ og derfor gÃ¥r det $y$ ud med det ene $y$ i nÃ¦vneren. SÃ¥ det der sker er: \n\n $z' = -\\frac{1}{y \\cdot \\cancel{y}} \\cdot \\cancel{y}(b - ay)$"},
        {
          "skridt": "z' = -\\frac{b}{y} + \\frac{ay}{y} = -b \\cdot \\frac{1}{y} + a",
          "argumentation": "BrÃ¸ken: $-\\frac{1}{y}$ ganges ind i parentesen og vi kan reducere udtrykket."},
        {
          "skridt": "z' = -b \\cdot \\frac{1}{y} + a = - b \\cdot z + a= a - b \\cdot z",
          "argumentation": "Vi erstatter $\\frac{1}{y}$ med $z$. Fordi at sÃ¥ er udtrykket for den afledte af $z$ en differentialligning hvor vi kender den generelle lÃ¸sning: \n\nDifferentialligningen:\n$y' = b - a \\cdot y$ \n\nHar den generelle lÃ¸sning:\n $y(x) = \\frac{b}{a} + c \\cdot e^{-ax}$"},
        {
          "skridt": "z(x) = \\frac{a}{b} + c_1 e^{-bx}",
          "argumentation": "Vi bestemmer lÃ¸sningen til differentialligningen for $z(x)$ ved brug af den generelle lÃ¸sning til differentialligningen med formen: $y' = b - a \\cdot y$"},
        {
          "skridt": "\\frac{1}{y(x)} = \\frac{a}{b} + c_1 e^{-bx}",
          "argumentation": "Erstatter $z(x)$ med dens funktionsforskrift, for at kunne isolere $y(x)$ og dermed bestemme dens funktionsforskrift."},
        {
          "skridt": "\\cancel{y(x)} \\cdot (\\frac{1}{\\cancel{y(x)}}) = y(x) \\cdot (\\frac{a}{b} + c_1 e^{-bx}) \\Leftrightarrow 1 = y(x) \\cdot (\\frac{a}{b} + c_1 e^{-bx})",
          "argumentation": "Begynder at isolere $y(x)$ ved at gange begge sider af lighedstegnet med $y(x)$"},
        {
          "skridt": "\\frac{1}{\\frac{a}{b} + c_1 e^{-bx}} = \\frac{y(x) \\cdot \\cancel{(\\frac{a}{b} + c_1 e^{-bx}})}{\\cancel{\\frac{a}{b} + c_1 e^{-bx}}}",
          "argumentation": "Isolerer $y(x)$ ved at dividere begge sider af lighedstegnet med $\\frac{a}{b} + c_1 e^{-bx}$. \n\nTil eksamen vil man ogsÃ¥ bare kunne sige at man bruger reglen:\n\n$\\frac{1}{a} = b \\Leftrightarrow a = \\frac{1}{b}$"},
        {
          "skridt": "y(x) = \\frac{1}{\\frac{a}{b} + c_1 e^{-bx}}",
          "argumentation": "Nu har vi isoleret $y(x)$ men vi mangler at Ã¦ndre pÃ¥ udtrykkets struktur for at det passer til det udtryk vi skal bevise."},
        {
          "skridt": "y(x) = \\frac{\\frac{b}{a} \\cdot 1}{\\frac{b}{a} \\left( \\frac{a}{b} + c_1 e^{-bx} \\right)} = \\frac{\\frac{b}{a}}{1 + \\left( \\frac{b}{a} \\cdot c_1 e^{-bx} \\right)} = \\frac{\\frac{b}{a}}{1 + c e^{-bx}}",
          "argumentation": "Vi kan reducere brÃ¸ken pÃ¥ hÃ¸jre side af lighedstegnet ved at gange tÃ¦ller og nÃ¦vner med $\\frac{b}{a}$ Fordi det svarer til at gange med $1$ og derfor Ã¦ndrer det ikke pÃ¥ venstre side af lighedstegnet. \n\nBrÃ¸ken bliver ogsÃ¥ ganget ind i parentesen i nÃ¦vneren af brÃ¸ken, og i fÃ¸rste led:\n\n$\\frac{b}{a} \\cdot \\frac{a}{b} = 1$ \n\nOg i andet led bliver $c_1$ til $c$ fordi at $c_1$ er en konstant der bliver ganget med en anden konstant ($\\frac{b}{a}$) og dette kan reduceres sÃ¥dan her:\n\n $\\frac{b}{a} \\cdot c_1 = c$ \n\nDe to konstanter bliver altsÃ¥ trukket sammen til Ã©n konstant som vi kalder $c$."},
        {
          "skridt": "y(x) = \\frac{\\frac{b}{a}}{1 + c e^{-bx}}",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$."}
          ]
        },
    {
      "bevis": "8/9) Differentialligningsbevis: Forskudt eksponentiel vÃ¦kst",
      "sÃ¦tning": "Differentialligningen $y' = b - ay, \\quad a, \\ne 0$ \n\nHar den fuldstÃ¦ndige lÃ¸sning: $y(x) = \\frac{b}{a}+c e^{-ax}, \\quad$ hvor c er et tal.",
      "udfÃ¸relse": [
        {
          "skridt": "z = z(x) = b - a \\cdot y(x) = -a \\left( y(x) - \\frac{b}{a} \\right)",
          "argumentation": "Vi vil bevise at differentialligningen $y' = b - ay$ har den fuldstÃ¦ndige lÃ¸sning: $y(x) = \\frac{b}{a}+c e^{ax}$. Det gÃ¸r vi ved at starte med at antage at der findes en lÃ¸sning og pÃ¥ baggrund af den antagelse beviser at det er en lÃ¸sning med den form. SÃ¥ vi starter med at lave en hjÃ¦lpefunktion $z(x)$ som er en sammensat funktion med den funktion vi ikke kender formen af, for sÃ¥ at aflede funktionen med kÃ¦dereglen hvor vi kan anvende vores viden om differentialligningen altsÃ¥ den afledte."},
        {
          "skridt": "z' = -a \\cdot y'",
          "argumentation": "Vi afleder efter kÃ¦dereglen:\n\n$(f(g(x)))' = f'(g(x)) \\cdot g'(x)$ \n\nKÃ¦dereglen har i Ã¸vrigt ogsÃ¥ den gode egenskab at den siger at man skal af"},
        {
          "skridt": "z'  = -a (b - a y)",
          "argumentation": "Vi indsÃ¦tter differentialligningen pÃ¥ $y'$"},
        {
          "skridt": "z'  = -a z",
          "argumentation": "Vi erstatter y' med z fordi sÃ¥ har vi en. ny differentialligningen hvor vi kender lÃ¸sningen og dette kan vi bruge til den anden lÃ¸sning vi beviser."},
        {
          "skridt": "z(x) = c_1 e^{-a x}",
          "argumentation": "Vi indsÃ¦tter lÃ¸sningen til differentialligningen for $z(x)$ som vi lavede ud fra en sammensatfunktion"},
        {
          "skridt": "-a \\left( y(x) - \\frac{b}{a} \\right) = c_1 e^{-a x}",
          "argumentation": "Vi erstatter z(x) med dens forskfrift"},
        {
          "skridt": "y(x) - \\frac{b}{a} = c e^{-a x} ",
          "argumentation": "Vi dividerer med $a$ pÃ¥ begge sider ogsÃ¥ bliver konstanten $c_1$ fordi det at det er en konstant der bliver divideret med en anden konstant, sÃ¥ kan reduceres ved at sammentrÃ¦kke dem til en konstant og give nyt navn"},
        {
          "skridt": "y(x) = \\frac{b}{a} + c e^{-a x} ",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    },
    {
      "bevis": "10) Bayes' sÃ¦tning",
      "sÃ¦tning": "SÃ¦tning (Bayesâ€™): I et sandsynlighedsfelt (ğ‘¼, ğ‘·), hvor ğ‘¨ og ğ‘© er to vilkÃ¥rlige hÃ¦ndelser, gÃ¦lder \n\n $P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$",
      "udfÃ¸relse": [ 
        {
          "skridt": "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}",
          "argumentation": "Vi begynder med udtrykket for betinget sandsynlighed."},
        {
          "skridt": "P(A \\cap B) = P(A \\mid B) \\cdot P(B)",
          "argumentation": "Vi isolerer udtrykket for fÃ¦llesmÃ¦ngden ved at gange med $P(B)$ pÃ¥ begge sider."},
        {
          "skridt": "P(B \\mid A) = \\frac{P(B \\cap A)}{P(A)}",
          "argumentation": "Nu tager vi fat i udtrykket for betinget sandsynlighed men hvor de to sandsynligheder er byttet om pÃ¥."},
        {
          "skridt": "P(B \\cap A) = P(B \\mid A) \\cdot P(A)",
          "argumentation": "Vi isolerer udtrykket for fÃ¦llesmÃ¦ngden ved at gange med $P(A)$ pÃ¥ begge sider."},
        {
          "skridt": "P(B \\cap A) = P(A \\cap B)",
          "argumentation": "Vi viser at vi ved at fÃ¦llesmÃ¦ngden er den samme uagtet af rÃ¦kkefÃ¸lge af de to sandsynlighedsfelter."},
        {
          "skridt": "P(B \\mid A) \\cdot P(A) = P(A \\mid B) \\cdot P(B)",
          "argumentation": "Nu indsÃ¦tter vi de udtryk for fÃ¦llesmÃ¦ngden vi har fundet."},
        {
          "skridt": "P(B \\mid A) \\cdot P(A) = P(A \\mid B) \\cdot P(B) \\Leftrightarrow \\frac{P(B \\mid A) \\cdot P(A)}{P(B)} = \\frac{P(A \\mid B) \\cancel{\\cdot P(B)}}{\\cancel{P(B)}}",
          "argumentation": "Vi isolerer $P(A \\mid B)$ ved at dividere med $P(B)$ pÃ¥ begge sider."},
        {
          "skridt": "P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    },
    {
      "bevis": "10) Bayes' udvidede sÃ¦tning",
      "sÃ¦tning": "Lad B vÃ¦re en hÃ¦ndelse i et sandsynlighedsfelt (ğ‘¼, ğ‘·), og lad $A_1$, $A_2$, â€¦ , $A_k$ vÃ¦re disjunkte hÃ¦ndelser, sÃ¥ $A_1$ âˆª $A_2$ âˆª â‹¯ âˆª $A_k$ = ğ‘¼. Da gÃ¦lder, at \n\n$P(A_i|B) = \\frac{P(B|A_i) \\cdot P(A_i)}{P(B|A_1) \\cdot P(A_1) + P(B|A_2) \\cdot P(A_2) + ... + P(B|A_k) \\cdot P(A_k)}$",
      "udfÃ¸relse": [ 
        {
          "skridt": "P(A_i \\mid B) = \\frac{P(B \\mid A_i) \\cdot P(A_i)}{P(B)}",
          "argumentation": "Vi begynder med udtrykket for Bayes' sÃ¦tning som vi har bevist i beviset fÃ¸r det her."},
        {
          "skridt": "P(A_i \\mid B) = \\frac{P(B \\mid A_i) \\cdot P(A_i)}{P(B)}",
          "argumentation": "Vi begynder med udtrykket for Bayes' sÃ¦tning som vi har bevist i beviset fÃ¸r det her."},
        {
          "skridt": "P(B) = P(B \\mid A_1) \\cdot P(A_1) + P(B \\mid A_2) \\cdot P(A_2) + \\cdots + P(B \\mid A_k) \\cdot P(A_k)",
          "argumentation": "Eftersom vi ved at sandsynlighedsfeltet bestÃ¥r af disjunkte hÃ¦ndelser og at de udgÃ¸r $U$ sÃ¥ kan vi bruge udtrykket for total sandsynlighed til at beskrive $P(B)$ \n\nUdtrykket for total sandsynlighed kan bruges fordi at vi ved at hver gang hÃ¦ndelsen $B$ $A_1,A_2,...,A_k$ indtrÃ¦ffer, mÃ¥ det ske i prÃ¦cis Ã©n af de disjunkte hÃ¦ndelser. \n\nDet vil sige, at $B$ kan opdeles i bidrag fra hver enkelt $A_i$, og sandsynligheden for $B$ er derfor summen af sandsynlighederne for, at $B$ sker under forudsÃ¦tning af hvert $A_i$, vÃ¦gtet med sandsynligheden for netop det $A_i$"},
        {
          "skridt": "P(A_i \\mid B) = \\frac{P(B \\mid A_i) \\cdot P(A_i)}{P(B \\mid A_1) \\cdot P(A_1) + P(B \\mid A_2) \\cdot P(A_2) + \\cdot + P(B \\mid A_k) \\cdot P(A_k)}",
          "argumentation": "Vi indsÃ¦tter udtrykket for total sandsynlighed for $P(B)$ i udtrykket for Bayes' sÃ¦tning."},
        {
          "skridt": "P(A_i \\mid B) = \\frac{P(B \\mid A_i) \\cdot P(A_i)}{P(B \\mid A_1) \\cdot P(A_1) + P(B \\mid A_2) \\cdot P(A_2) + \\cdot + P(B \\mid A_k) \\cdot P(A_k)}",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare"}
      ]
    },
    {
      "bevis": "11) Diskriminantformlen",
      "sÃ¦tning": "Andengradsligningen $ax^2 + bx + c = 0 (a \\cancel{=} 0)$ Har: \n\n- Ingen lÃ¸sninger, hvis $d<0$\n\n- LÃ¸sningen $x=-\\frac{b}{2a}$ , hvis $d = 0$\n\n- De to lÃ¸sninger $\\frac{-b+\\sqrt{d}}{2a}$ og $\\frac{-b-\\sqrt{d}}{2a}$  hvis $d>0$ \n\nHvor diskriminanten $d$ er bestemt som $d = b^2-4ac$.",
      "udfÃ¸relse": [
        {
          "skridt": "ax^2 + bx + c = 0",
          "argumentation": "Vi begynder med udtrykket for andengradsligningen."},
        {
          "skridt": "4a \\cdot (ax^2 + bx + c) = 4a \\cdot 0",
          "argumentation": "Vi ganger med $4a$ pÃ¥ begge sider fordi vi starter med at arbejder os hen imod at fÃ¥ definitionen for diskriminanten $d$, i dette udtryk, fordi udtrykket vi skal bevise indeholder $d$ i sig."},
        {
          "skridt": "4a^2x^2 + 4abx + 4ac = 4a \\cdot 0 \\Leftrightarrow 4a^2x^2 + 4abx + 4ac = 0",
          "argumentation": "Vi ganger $4a$ ind i hvert led af parentesen og reducerer brÃ¸ken"},
        {
          "skridt": "4a^2x^2 + 4abx + 4ac + (b^2 - 4ac) = 0 + (b^2 - 4ac) \\Leftrightarrow 4a^2x^2 + 4abx + b^2 = d",
          "argumentation": "Vi lÃ¦gger formlen for diskriminanten: \n\n$b^2 - 4ac$ \n\nTil pÃ¥ begge sider af lighedstegnet. Det gÃ¸r at den hÃ¸jre side af lighedstegnet nu kan omskrives til $d$ fordi det ene og alene bestÃ¥r af formlen for diskriminanten. Dette er godt fordi at det endelige udtryk vi beviser indeholder $d$. og nu har vi altsÃ¥ et nyt udtryk for $d$ som vi kan anvende."},
        {
          "skridt": "4a^2x^2 + 4abx + b^2 = d \\Leftrightarrow  (2ax + b)^2 = d",
          "argumentation": "Vi reducerer vores nye udtryk for diskriminanten ved at lave kvadratkomplettering. Det betyder at vi opdagede at formen af udtrykket: \n\n $4a^2x^2 + 4abx + b^2$ \n\nSvarede til formen pÃ¥ resultatet af den fÃ¸rste kvadratsÃ¦tning, som er defineret som: 'kvadratet af fÃ¸rste led lagt sammen med kvadratet af andet led lagt sammen med det dobbelte produkt' \nEller med en formel ser det sÃ¥dan her ud:\n\n$(a+b)^2 = a^2 + b^2 + 2ab$ \n\nHer er kvadratet fÃ¸rste led: $4a^2x^2$ og kvadratet andet led: $b^2$ og det dobbelte produkt: $4abx$. Og derfor for at lave kvadrakomplettering skal vi tage kvadratroden af $4a^2x^2$ og $b^2$ \n\n$\\sqrt{4a^2x^2} = 2ax$ \n\n$\\sqrt{b^2}=b$"},
        {
          "skridt": "(2ax + b)^2 = d",
          "argumentation": "Nu har vi altsÃ¥ omskrevet udtrykket for funktionsvÃ¦rdien af en andengradsfunktion er lig 0 ved fÃ¸rst at omskrive os frem til formlen for diskriminanten ogsÃ¥ indsÃ¦tte $d$ og derfra har vi det her udtryk og det her udtryk kan faktisk bekrÃ¦fte to af $d$'s egenskaber som vi satte os for at bevise. \nVi kan nemlig her se hvordan antallet af lÃ¸sninger afhÃ¦nger af vÃ¦rdien som $d$ har. Hvis $d$ er negativ har vi ingen lÃ¸sninger fordi fÃ¸rste skridt i at bestemme rÃ¸dderne udfra $d$ i dette udtryk er at tage kvadratroden af begge sider og du kan ikke bestemme kvadratroden af et negativt tal. Hvis d er 0 sÃ¥ har vi Ã©n lÃ¸sning og hvis $d$ er positiv sÃ¥ har vi to lÃ¸sninger fordi kvadrat roden af et positivt tal har altid 2 lÃ¸sninger i bÃ¥de en positiv og negativ version fordi at minus gange minus giver plus."},
        {
          "skridt": "\\sqrt{(2ax + b)^2} = \\pm \\sqrt{d} \\Leftrightarrow 2ax + b = \\pm \\sqrt{d}",
          "argumentation": "For at kunne kommer videre med at bevise formlen for lÃ¸sningerne til en andengradsligning sÃ¥ forudsÃ¦tter vi os nu at $dâ‰¥0$, fordi det krÃ¦ves for at der findes mindst Ã©n lÃ¸sning. Og nÃ¥r det er antaget at $dâ‰¥0$ sÃ¥ kan vi tage kvadratroden af begge sider af lighedstegnet og begynde at isolere $x$. Dette bringer os tÃ¦tter pÃ¥ lÃ¸sningsformlen og viser samtidig diskrimanten $d$'s rolle i at bestemme lÃ¸sningerne til en andengradsligning."},
        {
          "skridt": "2ax + b = \\pm \\sqrt{d} \\Leftrightarrow 2ax = -b + \\pm \\sqrt{d}",
          "argumentation": "Vi rykker $b$ over pÃ¥ den anden side og Ã¦ndre fortegn."},
        {
          "skridt": "2ax = -b + \\pm \\sqrt{d} \\Leftrightarrow x = \\frac{-b + \\pm \\sqrt{d}}{2a}",
          "argumentation": "Vi dividerer med $2a$ pÃ¥ begge sider for at isolere $x$. Og kan nu se hvordan lÃ¸sningerne afhÃ¦nger af koeeficienterne $a$, $b$ og $c$ i den oprindelige andengradsligning og diskriminanten $d$."},
        {
          "skridt": "x = \\frac{-b + \\pm \\sqrt{d}}{2a}",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    },
    {
      "bevis": "12) Vinklen mellem to egentlige vektore",
    "sÃ¦tning": "Hvis $\\vec{a}$ og $\\vec{b}$ er egentlige vektorer, og $v$ er vinkel mellem dem, gÃ¦lder formlen: \n\n $cos(v)=\\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| \\cdot |\\vec{b}|}$",
    "udfÃ¸relse": [
      {
      "skridt": "\\vec{a} \\cdot \\vec {b} = |\\vec{a}| \\cdot |\\vec {b}| \\cdot cos(v)",
      "argumentation": "For at bevise formlen for vinklen mellem to vektorer, sÃ¥ starter vi faktisk med at bevise denne formel for skalarproduktet af to vektore: \n\n$\\vec{a} \\cdot \\vec {b} = |\\vec{a}| \\cdot |\\vec {b}| \\cdot cos(v)$\n\nFordi nÃ¥r den er bevist sÃ¥ kan vi bare isolere cos(v) og fÃ¥ formlen for vinklen mellem to vektorer."},
      {
        "argumentation": "Vi begynder beviset med at tegne de to egentlige vektore (to vektore der IKKE er nul-vektoren) $\\vec{a}$ og $\\vec{b}$ ind i et koodinatsystem, med vinklen imellem dem noteret med $v$. $\\vec{a}$ er placeret langs x-aksen og $\\vec{b}$ over $\\vec{a}$.\n\n I matematik sÃ¥ kan en vektor beskrives med kartesiske koordinater, og det er bare de normale, man skal ikke kunne begrebet det er bare fun fact. Men en vektor kan ogsÃ¥ beskrives med polÃ¦re koordinater. Her er vektoren beskrevet med dens lÃ¦ngde og vinkel. \n\nEksempel pÃ¥ en vilkÃ¥rlig vektor $\\vec{a}$ med en lÃ¦ngde pÃ¥ 5 og en vinkel pÃ¥ 45 grader beskrevet med polÃ¦re korrdinater: \n\n$\\vec{a}=(5, 45^{\\circ})$ \n\n Denne vinkel som en vektor 'har', er defineret som vinklen mÃ¥lt fra den positive akse, mod uret, til vektoren. Derfor har vektore som $\\vec{b}$ og $\\vec{a}$ ogsÃ¥ hver deres vinkler tilknyttet til sig. Som sagt skal vi bestemme en formel for vinklen mellem to vektore, sÃ¥ ved at vi i starten af beviset placerer $\\vec{a}$ pÃ¥ x-aksen sÃ¥ har vi automatisk sat $\\vec{b}$'s vinkel til at vÃ¦re den vinkel der er mellem de to vektore $\\vec{a}$ og $\\vec{b}$ fordi at $\\vec{b}$'s vinkel jo som sagt mÃ¥les fra den positive akse og mod uret, og nu ligger $\\vec{a}$ pÃ¥ den positive akse. Det er nemmere fordi sÃ¥ har vi ikke nogle ligegyldige vinkler at tage hÃ¸jde for og sÃ¥ bliver beviset nemmere. \n\nMen hvorfor kan vi 'bare' placere $\\vec{a}$ her?\nDet skal vi argumentere for inden vi gÃ¥r videre til at bevise formlen for vinklen mellem to vektore.",
        "billede": "billeder/vinkelmellemtovektore.png"},
      {
      "skridt": "|\\vec{a}-\\vec{b}|^2",
      "argumentation": "Selvom at mÃ¥let med beviset er at bevise formlen for vinklen mellem to vektore sÃ¥ bestÃ¥r det egentlige bevis af at bevise en formel for skalarproduktet og nÃ¥r vi kender dette udtryk, kan vi nemlig isolere $cos(v)$. Men med dÃ©t i mente sÃ¥ nÃ¥r vi skal argumentere hvorfor hvorfor vi bare kan placere vektor $\\vec{a}$ hvor det passer os bedst, skal vi altsÃ¥ argumentere for at skalarproduktet af to vektore ikke er afhÃ¦ngigt af andet end lÃ¦ngden pÃ¥ to vektore og vinklen imellem dem. \n\nFor at vise dÃ©t, bruger vi udtrykket for kvadratet af lÃ¦ngden af forskellen mellem to vilkÃ¥rlige vektorer $\\vec{a}$ og $\\vec{b}$. Det gÃ¸r vi fordi at med nogle fÃ¥ omskrivninger af dette udtryk kan vi vise at skalarproduktet af to vilkÃ¥rlige vektore $\\vec{a}$ og $\\vec{b}$ kun afhÃ¦nger af lÃ¦ngden af vektorerne og vinklen imellem dem â€“ ikke af hvor de starter i koordinatsystemet."}
      ,
      {
      "skridt": "|\\vec{a}-\\vec{b}|^2 = (\\vec{a}-\\vec{b}) \\cdot (\\vec{a}-\\vec{b})",
      "argumentation": "Vi starter med at omskrive udtrykket med denne regel: \n\n$|\\vec{a}|^2 = \\vec{a}^2 = \\vec{a} \\cdot \\vec{a}$"},
      {
      "skridt": "|\\vec{a}-\\vec{b}|^2 = (\\vec{a}-\\vec{b})^2",
      "argumentation": "Vi reducere sammentrÃ¦kker udtrykket til en kvadratsÃ¦tning."},
      {
      "skridt": "|\\vec{a}-\\vec{b}|^2 = \\vec{a}^2+\\vec{b}^2-2\\vec{a}\\vec{b}",
      "argumentation": "Vi oplÃ¸ser parentesen ved udregne kvadratsÃ¦tningen, som har formen af det vi kalder 'den anden kvadratsÃ¦tning' fordi at de to led i kvadratsÃ¦tningen, $\\vec{a}$ og $\\vec{b}$, bliver trukket fra hinanden. \n\nUdregningen af den anden kvadratsÃ¦tning fÃ¸lger denne regel: \n\n$(a-b)^2 = a^2 + b^2 - 2ab$ \n\nUden at have isoleret $\\vec{a}$ og $\\vec{b}$ fra hinanden, kan vi faktisk allerede se at skalarproduktet er â€œgemtâ€ i lÃ¦ngden af forskelsvektoren. Og den lÃ¦ngde afhÃ¦nger kun af afstanden mellem vektorernes spidser â€“ ikke af hvor vektorerne starter. Men for at gÃ¸re det endnu tydeligere som omskriver vi udtrykket og isolerer $\\vec{a}$ og $\\vec{b}$ fra resten."},
      {
      "skridt": "|\\vec{a}-\\vec{b}|^2 = |\\vec{a}|^2+|\\vec{b}|^2-2\\vec{a}\\vec{b}",
      "argumentation": "Vi Ã¦ndre udtrykkene for kvadratet af de to vektorer $\\vec{a}$ og $\\vec{b}$ til at vÃ¦re udtryk for kvadratet af lÃ¦ngden af de to vektorer, hvor vi bruger samme regel som tidligere: \n\n$\\vec{a}|^2 = \\vec{a}^2$"},
      {
        "skridt": "|\\vec{a}-\\vec{b}|^2+ 2\\vec{a}\\vec{b} = |\\vec{a}|^2+|\\vec{b}|^2",
        "argumentation": "Nu rykker vi ledet der indeholder udtrykket for skalarproduktet: \n\n$2\\vec{a}\\vec{b}$ \n\n Over pÃ¥ venstre side af lighedstegnet og Ã¦ndre fortegn."},
      {
        "skridt": "2\\vec{a}\\vec{b} = |\\vec{a}|^2+|\\vec{b}|^2-|\\vec{a}-\\vec{b}|^2",
        "argumentation": "Nu rykker vi ledet der indeholder udtrykket for kvadratet af lÃ¦ngden forskellen mellem to vektore: \n\n$|\\vec{a}-\\vec{b}|^2$ \n\n Over pÃ¥ hÃ¸jre side af lighedstegnet og Ã¦ndre fortegn."},
      {
      "skridt": "\\frac{\\cancel{2}\\vec{a}\\vec{b}}{\\cancel{2}} = \\frac{|\\vec{a}|^2+|\\vec{b}|^2-|\\vec{a}-\\vec{b}|^2}{2}",
      "argumentation": "Nu dividere vi med to pÃ¥ begge sider af lighedstegnet for at fÃ¥ skalarproduktet til at stÃ¥ for sig selv"},
      {
      "skridt": "\\vec{a} \\cdot \\vec{b} = \\frac{|\\vec{a}|^2+|\\vec{b}|^2+|\\vec{a}-\\vec{b}|^2}{2}",
      "argumentation": "Dermed er det bevist at skalarproduktet af to vilkÃ¥rlige vektore $\\vec{a}$ og $\\vec{b}$ kun afhÃ¦nger af lÃ¦ngden af vektorerne og vinklen imellem dem â€“ ikke af placering."},
      {
      "skridt": "\\vec{a} \\cdot \\vec{b} = \\frac{|\\vec{a}|^2+|\\vec{b}|^2+|\\vec{a}-\\vec{b}|^2}{2}",
      "argumentation": "Dermed er det bevist at skalarproduktet af to vilkÃ¥rlige vektore $\\vec{a}$ og $\\vec{b}$ kun afhÃ¦nger af lÃ¦ngden af vektorerne og vinklen imellem dem â€“ ikke af placering."},
      {
      "skridt": "\\vec{a} = \\begin{pmatrix} |\\vec{a}| \\\\ 0 \\end{pmatrix} \\quad \\text{og} \\quad \\vec{b} = \\begin{pmatrix} |\\vec{b}| \\cdot \\cos(v) \\\\ |\\vec{b}| \\cdot \\sin(v) \\end{pmatrix}",
      "argumentation": "Nu har vi argumenteret for hvorfor vi kan placere vektorene hvor vi vil i koordinatsystemet, da skalarproduktet kun afhÃ¦nger af lÃ¦ngde og vinkel og derfor begynder vi beviset med at beskrive hvad vi ved om vores to vektore. Som sagt tideligere er der to hovedtyper at beskrive vektore pÃ¥, nemlig med kartesiske og polÃ¦re koordinater. Men de her beskrivelser ligner jo ingen af dem? \n\nFor at forklare hvorfor vi beskriver dem sÃ¥dan som vi gÃ¸r skal vi tage fat i noget trigonometri. Hvis man har en vilkÃ¥rlig vektor kan den faktisk beskrives som en retvinklet trekant. vektorens x-koordinat er den hosliggende katete og vektorens y-koordinat er denn modstÃ¥ende katete og lÃ¦ngden af vektore er trekantens hypotenuse. Hvis vi nu har det i mente ogsÃ¥ tager fat i formlen for cosinus og sinus: \n\n$cos(v)=\\frac{hosliggende}{hypotenuse}$ \n\n$sin(v)=\\frac{modstÃ¥ende}{hypotenuse}$",
      "billede": "billeder/vinkelmellemtovektore.png"},
      {
      "skridt": "\\vec{a} = \\begin{pmatrix} |\\vec{a}| \\\\ 0 \\end{pmatrix} \\quad \\text{og} \\quad \\vec{b} = \\begin{pmatrix} |\\vec{b}| \\cdot \\cos(v) \\\\ |\\vec{b}| \\cdot \\sin(v) \\end{pmatrix}",
      "argumentation": "Hvis man har en vilkÃ¥rlig vektor $\\vec{a}$ sÃ¥ kan den faktisk beskrives som en retvinklet trekant. vektorens fÃ¸rste koordinat, $a_1$,  er lÃ¦ngden af den hosliggende katete og vektorens anden koordinat, $a_2$,  er lÃ¦ngden af den modstÃ¥ende katete og lÃ¦ngden af vektoren, $|\\vec{a}|$, er trekantens hypotenuse. Hvis vi nu husker det og vi sÃ¥ tager fat i formlen for cosinus og sinus: \n\n$cos(v)=\\frac{hosliggende}{hypotenuse}$ \n\n$sin(v)=\\frac{modstÃ¥ende}{hypotenuse}$ \n\nSÃ¥ kan vi lynhurtigt se at vi kan beskrive og omskrive udtrykkene for en vektors fÃ¸rste og anden koordinater pÃ¥ fÃ¸lgene mÃ¥de: \n\nFÃ¸rste koordinat: \n\n$cos(v)=\\frac{hosliggende}{hypotenuse} \\Leftrightarrow cos(v)=\\frac{a_1}{|\\vec{a}|}$ \n\n$cos(v) \\cdot |\\vec{a}|=\\frac{a_1 \\cdot \\cancel{|\\vec{a}|}}{\\cancel{|\\vec{a}|}} \\Leftrightarrow cos(v) \\cdot |\\vec{a}|=a_1$ \n\nAnden koordinat: \n\n$sin(v)=\\frac{modstÃ¥ende}{hypotenuse} \\Leftrightarrow sin(v)=\\frac{a_2}{|\\vec{a}|}$ \n\n$sin(v) \\cdot |\\vec{a}|=\\frac{a_2 \\cdot \\cancel{|\\vec{a}|}}{\\cancel{|\\vec{a}|}} \\Leftrightarrow sin(v) \\cdot |\\vec{a}|=a_2$ \n\nSamlet set kan en vilkÃ¥rlig vektor $\\vec{a}$ beskrives: \n\n$\\vec{a} = \\begin{pmatrix} |\\vec{a}| \\cdot cos(v^{\\circ}) \\\\ |\\vec{a}| \\cdot sin(v^{\\circ}) \\end{pmatrix}$",
      "billede": "billeder/vinkelmellemtovektore.png"},
      {
      "skridt": "\\vec{a} = \\begin{pmatrix} |\\vec{a}| \\\\ 0 \\end{pmatrix} \\quad \\text{og} \\quad \\vec{b} = \\begin{pmatrix} |\\vec{b}| \\cdot \\cos(v) \\\\ |\\vec{b}| \\cdot \\sin(v) \\end{pmatrix}",
      "argumentation": "Hvis vi sÃ¥ anvender denne omskrivning til $\\vec{a}$ sÃ¥ kan vi hurtigt se fordelen ved at placere $\\vec{a}$ langs x-aksen, fordi sÃ¥ ved vi at vinklen er $0$ og det kan bruges til at reducere og dermed udelukke nogle ellers ukendte variabler: \n\n$\\vec{a} = \\begin{pmatrix} |\\vec{a}| \\cdot cos(0^{\\circ}) \\\\ |\\vec{a}| \\cdot sin(0^{\\circ}) \\end{pmatrix}$ \n\nVi ved at $cos(0^{\\circ}) = 1$ og $sin(0^{\\circ}) = 0$. Derfor reduceres udtrykket for vektor $\\vec{a}$ til:\n\n$\\vec{a} = \\begin{pmatrix} |\\vec{a}| \\\\ 0) \\end{pmatrix}$ \n\nOg eftersom vi ikke kender til vinklen for $\\vec{b}$ sÃ¥ kan vi bare lade den stÃ¥ som det er."},
      {
      "skridt": "\\vec{a} \\cdot \\vec{b} = |\\vec{a}| \\cdot |\\vec{b}| \\cdot \\cos(v) + 0 \\cdot |\\vec{b}| \\cdot \\sin(v)",
      "argumentation": "Vi skal jo bevise en formel for skalarproduktet af to vektore og derfor er det passende nu hvor vi kan beskrive deres fÃ¸rste og anden koordinater at vi anvender dem i denne formel for skalarproduktet: \n\n$\\vec{a} \\cdot \\vec{b} = a_1 \\cdot b_1 + a_2 \\cdot b_2$"},
      {
      "skridt": "\\vec{a} \\cdot \\vec{b} = |\\vec{a}| \\cdot |\\vec{b}| \\cdot \\cos(v)",
      "argumentation": "Nu har vi i princippet bevist formlen for skalarproduktet af to vektore, og vi kan nu afslutte beviset ved at isolere $cos(v)$ og fÃ¥ formlen for vinklen mellem to vektore."},
      {
      "skridt": "\\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| \\cdot |\\vec{b}|} = \\frac{\\cancel{|\\vec{a}| \\cdot |\\vec{b}| \\cdot} \\cos(v)}{\\cancel{|\\vec{a}| \\cdot |\\vec{b}|}}",
      "argumentation": "Vi isolerer ved at dividere med: \n\n$|\\vec{a}| \\cdot |\\vec{b}| $\n\n PÃ¥ begge sider af lighedstegnet"},
      {
      "skridt": "\\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| \\cdot |\\vec{b}|} = \\cos(v)",
      "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"} 
    ]
    },
    {
      "bevis": "13) Induktionsbevis: Differentialkvotienten for funktioner med formen: x^n",
      "sÃ¦tning": "For alle $$n \\in \\mathbb{N}$$ og alle $$x \\in \\mathbb{R}$$ gÃ¦lder at $$(x^n)' = nx^{n-1}$$",
      "udfÃ¸relse": [
        {
          "skridt": "Introduktion",
          "argumentation": "Beviset er et induktionsbevis og et induktionsbevis bestÃ¥r af to skridt: \n\nInduktionens start:\nEt form for 'mini-bevis' hvor vi viser at reglen vi skal bevise gÃ¦lder for et bestemt tal.\nI dette tilfÃ¦lde er det nÃ¥r $n = 1$ at vi udfÃ¸rer induktionens start. \n\nInduktionsskridtet:\nPÃ¥ baggrund af det 'mini-bevis' vi lavede i induktionens start bygger vi en antagelse om at 'hvis det gÃ¦lder for et vilkÃ¥rligt tal $n$ sÃ¥ kan vi ogsÃ¥ bevise at det gÃ¦lder for et vilkÃ¥rligt tal $n+1$' \nAltsÃ¥ vi bygger en antagelse om at reglen gÃ¦lder for et vilkÃ¥rligt tal (pÃ¥ baggrund af induktionens start) ogsÃ¥ vil vi bevise at reglen ogsÃ¥ gÃ¦lder for tallet der kommer efter det vilkÃ¥rlige tal.\n\nMÃ¥let med denne to-delte strategi, som er det vi kalder et 'induktionsbevis' er at:\nnÃ¥r vi har bevist at reglen gÃ¦lder for et vilkÃ¥rligt tal $n$ OG at reglen gÃ¦lder for det tal der kommer efter det vilkÃ¥rlige tal $n$, sÃ¥ mÃ¥ reglen gÃ¦lde for alle tal $n$ kan vÃ¦re. \n\nDet her er betydning af tegnene i bevissÃ¦tningen:\nDet er givet at $n$ er et naturligt tal: $$n \\in \\mathbb{N}$$ \nDet betyder at $n$ er et positivt helt tal. \n\nDet er ogsÃ¥ bestemt at x er et reelt tal: $$x \\in \\mathbb{R}$$ \nDet betyder at x kan vÃ¦re et decimaltal eller et helt tal der bÃ¥de kan vÃ¦re positivt, negativt eller 0."},
        {
          "skridt": "\\frac{\\Delta y}{\\Delta x}=\\frac{(x_0 + h) - x_0}{(x_0 + h)- x_0} = 1",
          "argumentation": "Induktionens start: \nVi udfÃ¸rer induktionens start som et 'mini-bevis'. \n\nVi skal bevise at for en funktion $f(x)$ med forskriften: \n\n$f(x)=x$\n\nSÃ¥ kan funktionen $f(x)$'s differentialkvotient bestemmes med fÃ¸lgende formel:\n$(x^n)' = n \\cdot x^{n - 1}$ \n\nHvis vi anvender formlen pÃ¥ vores funktion $f(x)$:\n\n$(x^1)' = 1$ \n\nsÃ¥ fÃ¥r vi resultatet:\n$1\\cdot x^{1 - 1} = x^0 = 1$\n\nVi beviser at formlen virker nÃ¥r $f(x) = x$ som et hvert andet differentialregnings bevis, nemlig med tretrinsreglen:\n1. Bestem differenskvotienten \n2. Omskriv differenskvotienten \n3. UndersÃ¸g om differenskvotienten har en grÃ¦nsevÃ¦rdi for $\\Delta x \\to 0$ og i sÃ¥ fald bestem differentialkvoitenten. \n\nDe to punkter vi arbejder med i dette mini-bevis er: \n$(x_0, f(x_0))$ og $(x_0 + h, f(x_0 + h))$\n\nDet fÃ¸rste skridt i beviset er at vi bestemmer differenskvotienten til $1$ ved at dividere forskel i funktionsvÃ¦rdi med forskel i x-vÃ¦rdi."
        },
        {
          "skridt": "f'(x_0) = \\lim_{h \\to 0} \\left( \\frac{\\Delta y}{\\Delta x}\\right) = \\lim_{h \\to 0} \\left( \\frac{(x_0 + h) - x_0}{(x_0 + h) - x_0} \\right)=1",
          "argumentation": "Vi kan faktisk bevÃ¦ge os direkte videre til 3. skridt af tretrinsreglen.\nVi behÃ¸ver nemlig ikke at omskrive differenskvotienten nÃ¥r den er lig $1$ , fordi at vi allerede kender grÃ¦nsevÃ¦rdien.\nVi anvender $\\lim_{h \\to 0}$ \n\n Og vi har dermed bevist at nÃ¥r: $f(x)=x$ \n\n SÃ¥ gÃ¦lder formlen: $(x^n)'=n \\cdot x^{n-1}$ \n\nTil at bestemme differentialkvotienten for $f(x)$  \n\nAlt i alt viser induktionens start at formlen vi skal bevise virker nÃ¥r $n = 1$ og denne information anvendes i nÃ¦ste skridt, induktionsskridtet."
        },
        {
          "skridt": "(x^{n+1})' = (n + 1) x^{n+1 - 1} = (n + 1) x^n",
          "argumentation": "I induktionens start beviste vi at formlen gÃ¦lder nÃ¥r $n=1$. \nI induktionsskridtet bruger vi dette til at ANTAGE at hvis formlen gÃ¦lder for $n=1$ \nSÃ¥ gÃ¦lder formlen for en vilkÃ¥rlig naturlig vÃ¦rdi $n$. \n\nMed udgangspunkt i denne antagelse om at formlen gÃ¦lder for en vilkÃ¥rligt vÃ¦rdi for $n$ sÃ¥ vil vi bevise at formlen gÃ¦lder for $n + 1$ \n\nAltsÃ¥ at den ogsÃ¥ gÃ¦lder for tallet der kommer efter et vilkÃ¥rligt tal $n$\n\n Motivet bag denne bevismetode er at kunne sige 'Hvis formlen gÃ¦lder for $n$ OG $n+1$ sÃ¥ har vi bevist at formlen gÃ¦lder for et hvilken som helst vÃ¦rdi for $n$, OG det tal der kommer efter, sÃ¥ har vi dermed bevist at formlen virker for alle de vÃ¦rdier $n$ kan have. \n\nDette er kerneprincippet i induktionsbeviser:\nMan beviser en formel for Ã©t startpunkt, og derefter, at formlen kan overfÃ¸res fra Ã©t tal til det nÃ¦ste."},
        {
          "skridt": "(x^{n+1})' = (x \\cdot x^n)'",
          "argumentation": "Vi starter induktionsskridtet med at omskrive den afledte af $x^{n+1}$ med brug af denne regel: \n\n$a^r \\cdot a^s = a^{r+s}$ \n\nDette tillader os at bruge produktreglen til at bevÃ¦ge os videre i beviset."},
        {
          "skridt": "(x^{n+1})'=  (x \\cdot x^n)'=(x)'(x^n) + (x)(x^n)'",
          "argumentation": "Vi anvender produktreglen til omskrivning:\n\n $( f(x) \\cdot g(x))' = f'(x) \\cdot g(x) + f(x) \\cdot g'(x)$"},
        {
          "skridt": "(x^{n+1})'= (x)'(x^n) + (x)(x^n)'= 1 \\cdot x^n + x \\cdot n x^{n-1}",
          "argumentation": "Vi anvender disse to regler til at aflede og dermed reducere udtrykket: \n\n$(x)'=1$ \n\n$(x^{n})'=n \\cdot x^{n-1}$"},
        {
          "skridt": "(x^{n+1})'= 1 x^n + n x^n",
          "argumentation": "Vi anvender denne regel igen: \n\n$a^r \\cdot a^s = a^{r+s}$ \n\n PÃ¥ den mÃ¥de har vi nu et udtryk bestÃ¥ende af to led med en fÃ¦lles faktor $x^n$"},
        {
          "skridt": "(x^{n+1})= 1 x^n + n x^n=(n + 1)x^n",
          "argumentation": "Vi faktoriserer udtrykket"},
        {
          "skridt": "(x^{n+1})= (n + 1)x^n",
          "argumentation": "Dermed er ovenstÃ¥ende sÃ¦tning bevist $\\blacksquare$"}
      ]
    }
  ]
}